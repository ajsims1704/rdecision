
@article{swat_probonto_2016,
	title = {{ProbOnto}: ontology and knowledge base of probability distributions},
	volume = {32},
	issn = {1367-4811, 1367-4803},
	url = {https://academic.oup.com/bioinformatics/article/32/17/2719/2450721},
	doi = {10.1093/bioinformatics/btw170},
	shorttitle = {{ProbOnto}},
	abstract = {Abstract 
            Motivation: Probability distributions play a central role in mathematical and statistical modelling. The encoding, annotation and exchange of such models could be greatly simplified by a resource providing a common reference for the definition of probability distributions. Although some resources exist, no suitably detailed and complex ontology exists nor any database allowing programmatic access. 
            Results: {ProbOnto}, is an ontology-based knowledge base of probability distributions, featuring more than 80 uni- and multivariate distributions with their defining functions, characteristics, relationships and re-parameterization formulas. It can be used for model annotation and facilitates the encoding of distribution-based models, related functions and quantities. 
            Availability and Implementation:  http://probonto.org 
            Contact:  mjswat@ebi.ac.uk 
            Supplementary information:  Supplementary data are available at Bioinformatics online.},
	pages = {2719--2721},
	number = {17},
	journaltitle = {Bioinformatics},
	author = {Swat, Maciej J. and Grenon, Pierre and Wimalaratne, Sarala},
	urldate = {2024-01-09},
	date = {2016-09-01},
	langid = {english},
}

@report{rcoreteam,
	location = {Vienna, Austria},
	title = {R: A language and environment for statistical computing},
	url = {https://www.R-project.org/},
	type = {manual},
	author = {{R Core Team}},
	date = {2021},
}

@report{henry2020,
	title = {rlang: Functions for base types and core r and tidyverse features},
	url = {https://CRAN.R-project.org/package=rlang},
	type = {manual},
	author = {Henry, Lionel and Wickham, Hadley},
	date = {2020},
}

@article{naimark_half-cycle_2013,
	title = {The Half-Cycle Correction Revisited: Redemption of a Kludge},
	volume = {33},
	issn = {0272-989X, 1552-681X},
	url = {http://journals.sagepub.com/doi/10.1177/0272989X13501558},
	doi = {10.1177/0272989X13501558},
	shorttitle = {The Half-Cycle Correction Revisited},
	abstract = {Decision-analytic software commonly used to implement discrete Markov models requires transitions to occur between simulated health states either at the beginning or at the end of each cycle. The result is an over- or underestimation, respectively, of quality-adjusted life expectancy and cost, compared with the results that would be obtained if transitions were modeled to occur randomly throughout each cycle. The standard half-cycle correction ({HCC}) is used to remedy the bias. However, the standard approach to the {HCC} is problematic: It does not account for discounting or for the shape of intermediate state membership functions. Application of the standard approach to the {HCC} also has no numerical effect on the resulting incremental cost-effectiveness ratio or change in net health benefit under certain circumstances. Alternatives to the standard {HCC}, in order of ease of use, include no correction, the life-table approach, the cycle-tree method, and a correction based on Simpson’s rule. For less complex decision models in which the computational burden is not large, reducing the cycle length to a month or less and using no correction should result in small estimation biases. With more complex models, where cycle lengths larger than 1 month may be necessary to make computation feasible, we recommend the cycle tree approach. The latter is relatively easy to apply and has an intuitive appeal: Hypothetical subjects who transition from one state to another, on average halfway through a cycle, should receive half of the value associated with the state from which they come and half the value of the state to which they are going.},
	pages = {961--970},
	number = {7},
	journaltitle = {Medical Decision Making},
	shortjournal = {Med Decis Making},
	author = {Naimark, David M. J. and Kabboul, Nader N. and Krahn, Murray D.},
	urldate = {2023-03-07},
	date = {2013-10},
	langid = {english},
}

@article{naimark_half-cycle_2008,
	title = {The Half-Cycle Correction Explained: Two Alternative Pedagogical Approaches},
	volume = {28},
	issn = {0272-989X, 1552-681X},
	url = {http://journals.sagepub.com/doi/10.1177/0272989X08315241},
	doi = {10.1177/0272989X08315241},
	shorttitle = {The Half-Cycle Correction Explained},
	abstract = {Students of Markov decision models are often taught to add a half-cycle's worth of incremental utility to the cumulative total for each health state. The reason for this ``half-cycle correction'' is often illustrated by a graph of the proportion of the hypothetical Markov cohort remaining in a given state. The ideal graph is shown as a smooth, declining, curve that represents the transition of patients randomly throughout each cycle. On the same graph, the effect of the accounting of state membership at the end of each cycle in discrete, computer-based approximations of the ideal Markov process is shown. Students are able to clearly see that the cumulative incremental utility in the discrete case underestimates the desired quantity. Likewise, they find the concept of shifting the ideal curve to the right by one-half cycle to reduce the latter discrepancy to be intuitive. However, students often find the approximate equivalence of shifting the ideal state membership curve and adding a half-cycle's worth of incremental utility to the total for the state at the beginning of a discrete Markov process to be a difficult cognitive leap. This article describes 2 pedagogical devices, algebraic and intuitive/visual approaches, that may assist the instructor of Markov theory to convey the latter concept. Elements of adult learning theory are discussed, which may help the instructor to choose which approach to employ. Implementation of the half-cycle correction in commonly used decision-analytic software is also discussed.},
	pages = {706--712},
	number = {5},
	journaltitle = {Medical Decision Making},
	shortjournal = {Med Decis Making},
	author = {Naimark, David M. J. and Bott, Michelle and Krahn, Murray},
	urldate = {2023-03-07},
	date = {2008-09},
	langid = {english},
}

@article{barendregt_half-cycle_2009,
	title = {The Half-Cycle Correction: Banish Rather Than Explain It},
	volume = {29},
	issn = {0272-989X, 1552-681X},
	url = {http://journals.sagepub.com/doi/10.1177/0272989X09340585},
	doi = {10.1177/0272989X09340585},
	shorttitle = {The Half-Cycle Correction},
	abstract = {The half-cycle correction is often used in discrete Markov models to estimate state membership. This article shows that the correction, in addition to being unintuitive, actually produces the wrong results in many circumstances. These include quality-adjusted life year ({QALY}) weights and unit costs that differ by cycle. The half-cycle correction is also incompatible with discounting of the obtained stream of state membership. It is furthermore shown that the life table method of estimating state membership obtains correct results under these circumstances and is also much more transparent. The article concludes that the half-cycle correction should be dropped in favor of the life table method.},
	pages = {500--502},
	number = {4},
	journaltitle = {Medical Decision Making},
	shortjournal = {Med Decis Making},
	author = {Barendregt, Jan J.},
	urldate = {2023-03-07},
	date = {2009-07},
	langid = {english},
}

@book{xie2018a,
	location = {Boca Raton, Florida},
	title = {R markdown: The definitive guide},
	isbn = {978-1-138-35933-8},
	url = {https://bookdown.org/yihui/rmarkdown},
	publisher = {Chapman and Hall/{CRC}},
	author = {Xie, Yihui and Allaire, J.J. and Grolemund, Garrett},
	date = {2018},
	note = {tex.ids= xie2018},
}

@article{severens_discounting_2004,
	title = {Discounting Health Outcomes in Economic Evaluation: The Ongoing Debate},
	volume = {7},
	issn = {1098-3015},
	url = {https://doi.org/10.1111/j.1524-4733.2004.74002.x},
	doi = {10.1111/j.1524-4733.2004.74002.x},
	pages = {397--401},
	number = {4},
	journaltitle = {Value in Health},
	shortjournal = {Value in Health},
	author = {Severens, Johan L. and Milne, Richard J.},
	urldate = {2022-01-10},
	date = {2004-07-01},
	note = {Publisher: John Wiley \& Sons, Ltd},
}

@article{jenks2016,
	title = {Tegaderm {CHG} {IV} Securement Dressing for Central Venous and Arterial Catheter Insertion Sites: A {NICE} Medical Technology Guidance},
	volume = {14},
	issn = {1175-5652},
	url = {http://link.springer.com/10.1007/s40258-015-0202-5},
	doi = {10.1007/s40258-015-0202-5},
	pages = {135--149},
	number = {2},
	journaltitle = {Applied Health Economics and Health Policy},
	author = {Jenks, Michelle and Craig, Joyce and Green, William and Hewitt, Neil and Arber, Mick and Sims, Andrew J},
	date = {2016-04},
	note = {tex.ids= jenks2016a
publisher: Springer International Publishing},
}

@article{willits2014a,
	title = {{WatchBP} Home A for Opportunistically Detecting Atrial Fibrillation During Diagnosis and Monitoring of Hypertension: A {NICE} Medical Technology Guidance},
	volume = {12},
	issn = {1175-5652},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/24664995 http://link.springer.com/10.1007/s40258-014-0096-7},
	doi = {10.1007/s40258-014-0096-7},
	abstract = {The Microlife(®) '{WatchBP} Home A' oscillometric blood pressure monitor detects irregular pulse, suggestive of atrial fibrillation ({AF}). Early detection of {AF} can prevent thromboembolic stroke via anticoagulation therapy. The device was considered by the Medical Technologies Evaluation Programme of the {UK} National Institute for Health and Care Excellence ({NICE}). The sponsor (Microlife) identified 10 studies. These were reviewed by an External Assessment Centre ({EAC}) which considered three relevant to the decision problem, including one which found the device detected {AF} more accurately (sensitivity 96.8 \%, specificity 88.8 \%) than pulse palpation (87.2, 81.3 \%). The {EAC} concluded the technology had potential to improve detection of {AF}, but the three studies had uncertain external validity. From a cost-consequence model with a 1-year timeframe, the sponsor calculated the device would reduce electrocardiogram ({ECG}) referrals and prevent strokes, but incur anticoagulation therapy costs, with net {NHS} savings of {\textbackslash}pounds11.6 million and prevention of 221 strokes, annually. The {EAC} criticised the model for its limited time horizon, and its consideration of symptomatic {AF} patients who were outside the scope issued by {NICE}. The {EAC} applied a de novo Markov model, with a 10-year timeframe. The per use saving was calculated as {\textbackslash}pounds2.98 for asymptomatic patients aged 65-74 years and {\textbackslash}pounds4.26 for those aged 75-84 years, with the prevention of 53-117 nonfatal and 28-65 fatal strokes per 100,000 people screened. Following consideration by the {NICE} Medical Technologies Advisory Committee, {NICE} judged that the case for adoption was supported by the evidence (Medical Technologies Guidance 13; {MTG}13).},
	pages = {255--265},
	number = {3},
	journaltitle = {Applied Health Economics and Health Policy},
	author = {Willits, Iain and Keltie, Kim and Craig, Joyce and Sims, Andrew},
	date = {2014-06},
	pmid = {24664995},
	note = {tex.ids= willits2014b},
}

@article{detsky1997,
	title = {Primer on Medical Decision Analysis: Part 2—Building a Tree},
	volume = {17},
	issn = {0272-989X},
	url = {https://doi.org/10.1177/0272989X9701700202},
	doi = {10.1177/0272989X9701700202},
	abstract = {This part of a five-part series covering practical issues in the performance of decision analysis outlines the basic strategies for building decision trees. The authors offer six recommendations for building and programming decision trees. Following these six recommendations will facilitate performance of the sensitivity analyses required to achieve two goals. The first is to find modeling or programming errors, a process known as "debugging" the tree. The second is to determine the robustness of the qualitative conclusions drawn from the analysis. Key words: decision analysis; expected value; utility; sensitivity analysis; decision trees; probability. (Med Decis Making 1997;17: 126-135)},
	pages = {126--135},
	number = {2},
	journaltitle = {Medical Decision Making},
	shortjournal = {Med Decis Making},
	author = {Detsky, Allan S. and Naglie, Gary and Krahn, Murray D. and Redelmeier, Donald A. and Naimark, David},
	urldate = {2021-11-01},
	date = {1997-04-01},
	note = {Publisher: {SAGE} Publications Inc {STM}},
}

@article{magee1964,
	title = {Decision Trees for Decision Making},
	url = {https://hbr.org/1964/07/decision-trees-for-decision-making},
	journaltitle = {Harvard Business Review},
	author = {Magee, John F.},
	date = {1964-07},
}

@article{ryder2009,
	title = {Decision Analysis and Cost-Effectiveness Analysis},
	volume = {21},
	issn = {1040-7383},
	url = {https://www.sciencedirect.com/science/article/pii/S1040738309000689},
	doi = {10.1053/j.semss.2009.08.003},
	abstract = {Healthcare decision making can be complex, often requiring decision makers to weigh serious trade-offs, consider patients' values, and incorporate evidence in the face of uncertainty. Medical decisions are made implicitly by clinicians and other decision-makers daily. Decisions based largely on personal experience are subject to many biases. Decision analysis and cost-effectiveness analysis are systematic approaches used to support decision-making under conditions of uncertainty that involve important trade-offs. These mathematical tools can provide patients, physicians, and policy makers with a useful approach to complex medical decision making.},
	pages = {216--222},
	number = {4},
	journaltitle = {Evidence-Based Medicine for the Spine},
	shortjournal = {Seminars in Spine Surgery},
	author = {Ryder, Hilary F. and {McDonough}, Christene M. and Tosteson, Anna N.A. and Lurie, Jon D.},
	date = {2009-12-01},
	keywords = {cost-effectiveness analysis, decision analysis, medical decision making},
}

@report{goulet2021,
	title = {expm: Matrix exponential, log, etc},
	url = {https://CRAN.R-project.org/package=expm},
	type = {manual},
	author = {Goulet, Vincent and Dutang, Christophe and Maechler, Martin and Firth, David and Shapira, Marina and Stadelmann, Michael},
	date = {2021},
}

@article{fleurence2007,
	title = {Rates and Probabilities in Economic Modelling},
	volume = {25},
	issn = {1179-2027},
	url = {https://doi.org/10.2165/00019053-200725010-00002},
	doi = {10.2165/00019053-200725010-00002},
	abstract = {Economic modelling is increasingly being used to evaluate the cost effectiveness of health technologies. One of the requirements for good practice in modelling is appropriate application of rates and probabilities. In spite of previous descriptions of appropriate use of rates and probabilities, confusions persist beyond a simple understanding of their definitions. The objective of this article is to provide a concise guide to understanding the issues surrounding the use of rates and probabilities reported in the literature in economic models, and an understanding of when and how to transform them appropriately. The article begins by defining rates and probabilities and shows the essential difference between the two measures. Appropriate conversions between rates and probabilities are discussed, and simple examples are provided to illustrate the techniques and pitfalls. How the transformed rates and probabilities may be used in economic models is then described and some recommendations are suggested.},
	pages = {3--6},
	number = {1},
	journaltitle = {{PharmacoEconomics}},
	shortjournal = {{PharmacoEconomics}},
	author = {Fleurence, Rachael L. and Hollenbeak, Christopher S.},
	date = {2007-01-01},
}

@article{welton2005,
	title = {Estimation of Markov Chain Transition Probabilities and Rates from Fully and Partially Observed Data: Uncertainty Propagation, Evidence Synthesis, and Model Calibration},
	volume = {25},
	issn = {0272-989X},
	url = {https://doi.org/10.1177/0272989X05282637},
	doi = {10.1177/0272989X05282637},
	abstract = {Markov transition models are frequently used to model disease progression. The authors show how the solution to Kolmogorov?s forward equations can be exploited to map between transition rates and probabilities from probability data in multistate models. They provide a uniform, Bayesian treatment of estimation and propagation of uncertainty of transition rates and probabilities when 1) observations are available on all transitions and exact time at risk in each state (fully observed data) and 2) observations are on initial state and final state after a fixed interval of time but not on the sequence of transitions (partially observed data). The authors show how underlying transition rates can be recovered from partially observed data using Markov chain Monte Carlo methods in {WinBUGS}, and they suggest diagnostics to investigate inconsistencies between evidence from different starting states. An illustrative example for a 3-state model is given, which shows how the methods extend to more complex Markov models using the software {WBDiff} to compute solutions. Finally, the authors illustrate how to statistically combine data from multiple sources, including partially observed data at several follow-up times and also how to calibrate a Markov model to be consistent with data from one specific study.},
	pages = {633--645},
	number = {6},
	journaltitle = {Medical Decision Making},
	shortjournal = {Med Decis Making},
	author = {Welton, Nicky J. and Ades, A. E.},
	urldate = {2021-08-18},
	date = {2005-11-01},
	note = {Publisher: {SAGE} Publications Inc {STM}},
}

@article{tirschwell2018,
	title = {Cost-effectiveness of percutaneous patent foramen ovale closure as secondary stroke prevention},
	volume = {21},
	issn = {1369-6998},
	url = {https://doi.org/10.1080/13696998.2018.1456445},
	doi = {10.1080/13696998.2018.1456445},
	pages = {656--665},
	number = {7},
	journaltitle = {Journal of Medical Economics},
	shortjournal = {null},
	author = {Tirschwell, David L. and Turner, Mark and Thaler, David and Choulerton, James and Marks, David and Carroll, John and {MacDonald}, Lee and Smalling, Richard W. and Koullick, Maria and Gu, Ning Yan and Saver, Jeffrey L.},
	date = {2018-07-03},
	note = {Publisher: Taylor \& Francis},
}

@article{jones2017,
	title = {A Procedure for Deriving Formulas to Convert Transition Rates to Probabilities for Multistate Markov Models},
	volume = {37},
	issn = {0272-989X},
	url = {https://doi.org/10.1177/0272989X17696997},
	doi = {10.1177/0272989X17696997},
	abstract = {For health-economic analyses that use multistate Markov models, it is often necessary to convert from transition rates to transition probabilities, and for probabilistic sensitivity analysis and other purposes it is useful to have explicit algebraic formulas for these conversions, to avoid having to resort to numerical methods. However, if there are four or more states then the formulas can be extremely complicated. These calculations can be made using packages such as R, but many analysts and other stakeholders still prefer to use spreadsheets for these decision models. We describe a procedure for deriving formulas that use intermediate variables so that each individual formula is reasonably simple. Once the formulas have been derived, the calculations can be performed in Excel or similar software. The procedure is illustrated by several examples and we discuss how to use a computer algebra system to assist with it. The procedure works in a wide variety of scenarios but cannot be employed when there are several backward transitions and the characteristic equation has no algebraic solution, or when the eigenvalues of the transition rate matrix are very close to each other.},
	pages = {779--789},
	number = {7},
	journaltitle = {Medical Decision Making},
	shortjournal = {Med Decis Making},
	author = {Jones, Edmund and Epstein, David and García-Mochón, Leticia},
	urldate = {2021-08-13},
	date = {2017-10-01},
	note = {Publisher: {SAGE} Publications Inc {STM}},
}

@report{willits2012a,
	title = {Cost impact of the {WatchBP} Home A used in a primary healthcare clinic environment},
	url = {https://www.nice.org.uk/guidance/MTG13},
	institution = {National Institute for Health and Care Excellence},
	type = {{NICE} External Assessment Centre Report},
	author = {Willits, I. and Keltie, Kim and Craig, Joyce and Sims, Andrew J.},
	date = {2012-08},
}

@article{petrou2011,
	title = {Economic evaluation using decision analytical modelling: design, conduct, analysis, and reporting},
	volume = {342},
	url = {http://www.bmj.com/content/342/bmj.d1766.abstract},
	doi = {10.1136/bmj.d1766},
	abstract = {Evidence relating to healthcare decisions often comes from more than one study. Decision analytical modelling can be used as a basis for economic evaluations in these situations.Economic evaluations are increasingly conducted alongside randomised controlled trials, providing researchers with individual patient data to estimate cost effectiveness.1 However, randomised trials do not always provide a sufficient basis for economic evaluations used to inform regulatory and reimbursement decisions. For example, a single trial might not compare all the available options, provide evidence on all relevant inputs, or be conducted over a long enough time to capture differences in economic outcomes (or even measure those outcomes).2 In addition, reliance on a single trial may mean ignoring evidence from other trials, meta-analyses, and observational studies. Under these circumstances, decision analytical modelling provides an alternative framework for economic evaluation.Decision analytical modelling compares the expected costs and consequences of decision options by synthesising information from multiple sources and applying mathematical techniques, usually with computer software. The aim is to provide decision makers with the best available evidence to reach a decision—for example, should a new drug be adopted? Following on from our article on trial based economic evaluations,1 we outline issues relating to the design, conduct, analysis, and reporting of economic evaluations using decision analytical modelling. Glossary of {termsCost} effectiveness acceptability curve—Graphical depiction of the probability that a health intervention is cost effective across a range of willingness to pay thresholds held by decision makers for the health outcome of {interestCost} effectiveness plane—Graphical depiction of difference in effectiveness between the new treatment and the comparator against the difference in {costDiscounting}—The practice of reducing future costs and health outcomes to present values Health utilities—Preference based outcomes normally represented on a scale where 0 represents death and 1 represents perfect …},
	pages = {d1766},
	journaltitle = {{BMJ}},
	shortjournal = {{BMJ}},
	author = {Petrou, Stavros and Gray, Alastair},
	date = {2011-04-11},
}

@article{dong2006,
	title = {Early assessment of the likely cost-effectiveness of a new technology: A Markov model with probabilistic sensitivity analysis of computer-assisted total knee replacement},
	volume = {22},
	issn = {0266-4623},
	url = {https://www.cambridge.org/core/article/early-assessment-of-the-likely-costeffectiveness-of-a-new-technology-a-markov-model-with-probabilistic-sensitivity-analysis-of-computerassisted-total-knee-replacement/2B99B141DDBD3F58FBD57F90425CA23B},
	doi = {10.1017/S0266462306051014},
	abstract = {Objectives: The objective of this study is to apply a Markov model to compare cost-effectiveness of total knee replacement ({TKR}) using computer-assisted surgery ({CAS}) with that of {TKR} using a conventional manual method in the absence of formal clinical trial evidence.Methods: A structured search was carried out to identify evidence relating to the clinical outcome, cost, and effectiveness of {TKR}. Nine Markov states were identified based on the progress of the disease after {TKR}. Effectiveness was expressed by quality-adjusted life years ({QALYs}). The simulation was carried out initially for 120 cycles of a month each, starting with 1,000 {TKRs}. A discount rate of 3.5 percent was used for both cost and effectiveness in the incremental cost-effectiveness analysis. Then, a probabilistic sensitivity analysis was carried out using a Monte Carlo approach with 10,000 iterations.Results: Computer-assisted {TKR} was a long-term cost-effective technology, but the {QALYs} gained were small. After the first 2 years, the incremental cost per {QALY} of computer-assisted {TKR} was dominant because of cheaper and more {QALYs}. The incremental cost-effectiveness ratio ({ICER}) was sensitive to the “effect of {CAS},” to the {CAS} extra cost, and to the utility of the state “Normal health after primary {TKR},” but it was not sensitive to utilities of other Markov states. Both probabilistic and deterministic analyses produced similar cumulative serious or minor complication rates and complex or simple revision rates. They also produced similar {ICERs}.Conclusions: Compared with conventional {TKR}, computer-assisted {TKR} is a cost-saving technology in the long-term and may offer small additional {QALYs}. The “effect of {CAS}” is to reduce revision rates and complications through more accurate and precise alignment, and although the conclusions from the model, even when allowing for a full probabilistic analysis of uncertainty, are clear, the “effect of {CAS}” on the rate of revisions awaits long-term clinical evidence.},
	pages = {191--202},
	number = {2},
	journaltitle = {International Journal of Technology Assessment in Health Care},
	author = {Dong, Hengjin and Buxton, Martin},
	date = {2006},
	note = {Edition: 2006/03/28
Publisher: Cambridge University Press},
	keywords = {Computer-assisted surgery, Cost-effectiveness analysis, Incremental cost-effectiveness ratio, Markov model, {QALY}, Total knee replacement},
}

@article{grill2005,
	title = {Comparing the clinical effectiveness of different new-born hearing screening strategies. A decision analysis},
	volume = {5},
	issn = {1471-2458},
	url = {https://doi.org/10.1186/1471-2458-5-12},
	doi = {10.1186/1471-2458-5-12},
	abstract = {Children with congenital hearing impairment benefit from early detection and treatment. At present, no model exists which explicitly quantifies the effectiveness of universal newborn hearing screening ({UNHS}) versus other programme alternatives in terms of early diagnosis. It has yet to be considered whether early diagnosis (within the first few months) of hearing impairment is of importance with regard to the further development of the child compared with effects resulting from a later diagnosis. The objective was to systematically compare two screening strategies for the early detection of new-born hearing disorders, {UNHS} and risk factor screening, with no systematic screening regarding their influence on early diagnosis.},
	pages = {12},
	number = {1},
	journaltitle = {{BMC} Public Health},
	shortjournal = {{BMC} Public Health},
	author = {Grill, Eva and Hessel, Franz and Siebert, Uwe and Schnell-Inderst, Petra and Kunze, Silke and Nickisch, Andreas and Wasem, Jürgen},
	date = {2005-01-31},
}

@article{beck1983,
	title = {The Markov Process in Medical Prognosis},
	volume = {3},
	issn = {0272-989X},
	url = {https://doi.org/10.1177/0272989X8300300403},
	doi = {10.1177/0272989X8300300403},
	abstract = {The physician's estimate of prognosis under alternative treatment plans is a principal factor in therapeutic decision making. Current methods of reporting prognosis, which include five-year survivals, survival curves, and quality-adjusted life expec tancy, are crude estimates of natural history. In this paper we describe a general- purpose model of medical prognosis based on the Markov process and show how this simple mathematical tool may be used to generate detailed and accurate assessments of life expectancy and health status. (Med Decis Making 3:419-458, 1983)},
	pages = {419--458},
	number = {4},
	journaltitle = {Medical Decision Making},
	shortjournal = {Med Decis Making},
	author = {Beck, J.Robert and Pauker, Stephen G.},
	urldate = {2021-08-10},
	date = {1983-12-01},
	note = {Publisher: {SAGE} Publications Inc {STM}},
}

@article{miller1994,
	title = {Determining Transition Probabilities: Confusion and Suggestions},
	volume = {14},
	issn = {0272-989X},
	url = {https://doi.org/10.1177/0272989X9401400107},
	doi = {10.1177/0272989X9401400107},
	abstract = {Confusion regarding proper use of the terms rate and risk persists in the literature. This has implications for the proper modeling of prognosis and transition between health states in decision analysis and related techniques. The issue is complicated by the plethora of terms related to rate and risk. Although the suggestion to use the terms force and probability as substitutes for rate and risk has some appeal, the change in terminology by itself is unlikely to solve all the confusion or misuse of terms. This paper clarifies the proper definitions and estimations of rates and risks and suggests critical factors for the decision analyst to re member when using, modeling, or interpreting transition rates and risks. Key words: decision models; rate; risk; force; probability; transitions. (Med Decis Making 1994;14:52-58)},
	pages = {52--58},
	number = {1},
	journaltitle = {Medical Decision Making},
	shortjournal = {Med Decis Making},
	author = {Miller, Douglas K. and Homan, Sharon M.},
	urldate = {2021-08-10},
	date = {1994-02-01},
	note = {Publisher: {SAGE} Publications Inc {STM}},
}

@article{siebert2012,
	title = {State-Transition Modeling: A Report of the {ISPOR}-{SMDM} Modeling Good Research Practices Task Force-3},
	volume = {15},
	issn = {1098-3015},
	url = {https://www.sciencedirect.com/science/article/pii/S1098301512016543},
	doi = {10.1016/j.jval.2012.06.014},
	abstract = {State-transition modeling is an intuitive, flexible, and transparent approach of computer-based decision-analytic modeling including both Markov model cohort simulation and individual-based (first-order Monte Carlo) microsimulation. Conceptualizing a decision problem in terms of a set of (health) states and transitions among these states, state-transition modeling is one of the most widespread modeling techniques in clinical decision analysis, health technology assessment, and health-economic evaluation. State-transition models have been used in many different populations and diseases, and their applications range from personalized health care strategies to public health programs. Most frequently, state-transition models are used in the evaluation of risk factor interventions, screening, diagnostic procedures, treatment strategies, and disease management programs. The goal of this article was to provide consensus-based guidelines for the application of state-transition models in the context of health care. We structured the best practice recommendations in the following sections: choice of model type (cohort vs. individual-level model), model structure, model parameters, analysis, reporting, and communication. In each of these sections, we give a brief description, address the issues that are of particular relevance to the application of state-transition models, give specific examples from the literature, and provide best practice recommendations for state-transition modeling. These recommendations are directed both to modelers and to users of modeling results such as clinicians, clinical guideline developers, manufacturers, or policymakers.},
	pages = {812--820},
	number = {6},
	journaltitle = {Value in Health},
	shortjournal = {Value in Health},
	author = {Siebert, Uwe and Alagoz, Oguzhan and Bayoumi, Ahmed M. and Jahn, Beate and Owens, Douglas K. and Cohen, David J. and Kuntz, Karen M.},
	date = {2012-09-01},
	keywords = {Markov models, decision-analytic modeling, guidelines, state-transition modeling},
}

@article{kahn1962,
	title = {Topological sorting of large networks},
	volume = {5},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/368996.369025},
	doi = {10.1145/368996.369025},
	abstract = {Topological Sorting is a procedure required for many problems involving analysis of networks. An example of one such problem is {PERT}. The present paper presents a very general method for obtaining topological order. It permits treatment of larger networks than can be handled on present procedures and achieves this with greater efficiency. Although the procedure can be adapted to any machine, it is discussed in terms of the 7090. A {PERT} network of 30,000 activities can be ordered in less than one hour of machine time. The method was developed as a byproduct of procedure needed by Westinghouse, Baltimore. It has not been programmed and at present there are no plans to implement it. In regard to the techniques described, Westinghouse's present and anticipated needs are completely served by the Lockheed program, which is in current use.},
	pages = {558--562},
	number = {11},
	journaltitle = {Communications of the {ACM}},
	author = {Kahn, A. B.},
	date = {1962-11},
	note = {Number of pages: 5
Publisher: Association for Computing Machinery
tex.address: New York, {NY}, {USA}
tex.issue\_date: Nov. 1962},
}

@article{gansner1993,
	title = {A technique for drawing directed graphs},
	volume = {19},
	issn = {1939-3520},
	doi = {10.1109/32.221135},
	abstract = {A four-pass algorithm for drawing directed graphs is presented. The fist pass finds an optimal rank assignment using a network simplex algorithm. The seconds pass sets the vertex order within ranks by an iterative heuristic, incorporating a novel weight function and local transpositions to reduce crossings. The third pass finds optimal coordinates for nodes by constructing and ranking an auxiliary graph. The fourth pass makes splines to draw edges. The algorithm creates good drawings and is fast.},
	pages = {214--230},
	number = {3},
	journaltitle = {{IEEE} Transactions on Software Engineering},
	shortjournal = {{IEEE} Transactions on Software Engineering},
	author = {Gansner, E. R. and Koutsofios, E. and North, S. C. and Vo, K-P.},
	date = {1993-03},
}

@article{wickham2011,
	title = {testthat: Get started with testing},
	volume = {3},
	url = {https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf},
	pages = {5--10},
	journaltitle = {The R Journal},
	author = {Wickham, Hadley},
	date = {2011},
}

@book{gross2013,
	edition = {2nd},
	title = {Handbook of Graph Theory},
	isbn = {978-0-429-19275-3},
	url = {https://doi.org/10.1201/b16132},
	pagetotal = {1630},
	publisher = {Chapman and Hall/{CRC}.},
	author = {Gross, J. L. and Yellen, J. and Zhang, P.},
	date = {2013},
}

@report{allaire2020,
	title = {rmarkdown: Dynamic documents for r},
	url = {https://github.com/rstudio/rmarkdown},
	type = {manual},
	author = {Allaire, {JJ} and Xie, Yihui and {McPherson}, Jonathan and Luraschi, Javier and Ushey, Kevin and Atkins, Aron and Wickham, Hadley and Cheng, Joe and Chang, Winston and Iannone, Richard},
	date = {2020},
}

@report{chang2020,
	title = {R6: Encapsulated classes with reference semantics},
	url = {https://CRAN.R-project.org/package=R6},
	type = {manual},
	author = {Chang, Winston},
	date = {2020},
}

@report{wickham2020,
	title = {devtools: Tools to make developing r packages easier},
	url = {https://CRAN.R-project.org/package=devtools},
	type = {manual},
	author = {Wickham, Hadley and Hester, Jim and Chang, Winston},
	date = {2020},
}

@book{xie2020,
	location = {Boca Raton, Florida},
	title = {R markdown cookbook},
	isbn = {978-0-367-56383-7},
	url = {https://bookdown.org/yihui/rmarkdown-cookbook},
	publisher = {Chapman and Hall/{CRC}},
	author = {Xie, Yihui and Dervieux, Christophe and Riederer, Emily},
	date = {2020},
}

@inreference{wikipedia2021,
	title = {Glossary of graph theory},
	url = {https://en.wikipedia.org/wiki/Glossary_of_graph_theory},
	booktitle = {Wikipedia},
	author = {{Wikipedia}},
	date = {2021},
}

@article{kaminski2018,
	title = {A framework for sensitivity analysis of decision trees},
	volume = {26},
	doi = {10.1007/s10100-017-0479-6},
	pages = {135--159},
	journaltitle = {Central European Journal of Operational Research},
	author = {Kamiński, Bogumil and Jakubczyk, Michal and Szufel, Przemyslaw},
	date = {2018},
}

@report{NICE2020a,
	title = {Plus Sutures for preventing surgical site infection},
	url = {https://www.nice.org.uk/guidance/mib204},
	number = {{MIB} 204},
	institution = {National Institute for Health and Care Excellence},
	type = {Medtech innovation briefing},
	author = {{NICE}},
	date = {2020-02-04},
	note = {{ISBN}: 978-1-4731-3675-5},
}

@article{tilford1981,
	title = {Tidier Drawings of Trees},
	volume = {7},
	issn = {1939-3520},
	url = {http://doi.ieeecomputersociety.org/10.1109/TSE.1981.234519},
	doi = {10.1109/TSE.1981.234519},
	pages = {223--228},
	number = {2},
	journaltitle = {{IEEE} Transactions on Software Engineering},
	shortjournal = {{IEEE} Transactions on Software Engineering},
	author = {Tilford, J. and Reingold, E.},
	date = {1981-03},
	keywords = {Data Structures, Tree Structures, Trees},
}

@report{walker1989,
	location = {Chapel Hill},
	title = {A node-positioning algorithm for general trees},
	url = {http://www.cs.unc.edu/techreports/89-034.pdf},
	abstract = {Drawing a tree consists of two stages: determining the position of each node, and actually rendering the individuals nodes and interconnecting branches. The algorithm described in this paper is concerned with the first stage: given a list of nodes. an indication of the hierarchical relationship among them. and their shape and size, wrere should each node be positioned for optimal aesthetic effect?

This algorithm determines the positions of the nodes for any arbitrary general tree. It is the most desirable positioning with respect to certain widely- accepted heuristics. The positioning, specified in x, y coordinates, minimizes the width of the tree. In a general tree, there is no limit on the number of off- spring per node; this contrasts with binary and ternary trees, for example, which are trees with a limit of 2 and 3 offspring per node. This algorithm oper- ates in time O(N), where N is the number of nodes in the tree.

Previously, most tree drawings have been positioned by the sure hand of a human graphic designer. Many computer-generated positionings have been either trivial or contained irregularities. Earlier work by Wetherell and Shannon (1979) and Tilford (1981), upon which this algorithm builds, failed to correctly position the interior nodes of some trees. Radack (1988), also building on Tilford's work, has solved this same problem with a different method which makes four passes. The algorithm presented here correctly positions a tree's nodes using only two passes. It also handles several practical considerations: alternate orientations of the tree, variable node sizes, and out-of-bounds conditions.},
	number = {{TR} 89-034},
	institution = {University of North Carolina},
	type = {Technical Report},
	author = {Walker, John Q.},
	date = {1989-09},
}

@article{sonnenberg1993,
	title = {Markov Models in Medical Decision Making: A Practical Guide},
	volume = {13},
	issn = {0272-989X},
	url = {http://mdm.sagepub.com/cgi/doi/10.1177/0272989X9301300409},
	doi = {10.1177/0272989X9301300409},
	pages = {322--338},
	number = {4},
	journaltitle = {Medical Decision Making},
	author = {Sonnenberg, F. A. and Beck, J. R.},
	date = {1993},
	note = {tex.ids: sonnenberg1993a, sonnenberg:1993a},
}

@article{chancellor1997,
	title = {Modelling the cost effectiveness of Lamivudine/Zidovudine combination therapy in {HIV} infection},
	volume = {12},
	pages = {54--66},
	number = {1},
	journaltitle = {Pharmacoeconomics},
	author = {Chancellor, Jeremy V. and Hill, Andrew M. and Sabin, Caroline A. and Simpson, Kit N. and Youle, Mike},
	date = {1997},
}

@article{evans1997,
	title = {Economic evaluation of oral Sumatriptan compared with oral Caffeine/Ergotamine for migraine},
	volume = {12},
	pages = {565--577},
	number = {5},
	journaltitle = {Pharmacoeconomics},
	author = {Evans, Kenneth W. and Boan, John A. and Evans, John L. and Shuaib, Ashfaq},
	date = {1997},
}

@article{goeree1999,
	title = {Economic Evaluation of Long Term Management Strategies for Erosive Oesophagitis},
	volume = {16},
	issn = {1179-2027},
	url = {https://doi.org/10.2165/00019053-199916060-00007},
	doi = {10.2165/00019053-199916060-00007},
	abstract = {Objective: To compare the expected costs and outcomes of alternative strategies for the management of patients with erosive oesophagitis.},
	pages = {679--697},
	number = {6},
	journaltitle = {{PharmacoEconomics}},
	shortjournal = {{PharmacoEconomics}},
	author = {Goeree, Ron and O’Brien, Bernie and Hunt, Richard and Blackhouse, Gordon and Willan, Andrew and Watson, Jan},
	date = {1999-12-01},
}

@article{goeree2002,
	title = {Cost-Effectiveness and Cost-Utility of Long-Term Management Strategies for Heartburn},
	volume = {5},
	issn = {1098-3015},
	url = {http://www.sciencedirect.com/science/article/pii/S1098301510600228},
	doi = {10.1046/j.1524-4733.2002.54145.x},
	abstract = {Objectives
To compare the expected costs and outcomes of seven alternative long-term primary care strategies for the management of patients with moderate-to-severe heartburn over a 1-year period.
Methods
A decision-analytic model was developed to estimate costs and effects (weeks with heartburn symptoms and quality adjusted life years {QALYs}]) for each strategy. Meta-analyses were used to synthesize acute treatment and maintenance studies and physician surveys to collect information on patient management. The impact of uncertainty on the base case results was assessed using probabilistic sensitivity analysis. Probability distributions were defined for key model parameters and techniques of Monte Carlo simulation were used to draw values from these distributions. Cost-effectiveness acceptability curves ({CEACs}) conditional on the monetary value decision makers are willing to pay for a symptom-free day or {QALY} were created for each strategy.
Results
In the base case, no strategy was strictly dominated by any other strategy. However, two strategies (maintenance H2-receptor antagonists H2RA] and step-down proton pump inhibitor {PPI}]) were dominated through principles of extended dominance. The least costly and least effective strategy was intermittent H2RA, while maintenance {PPI} was the most costly and most effective.
Conclusions
This analysis showed that the best way of managing patients with heartburn depends on how much society is willing to pay to achieve health improvements. Based on the commonly quoted threshold of \$50,000 per {QALY}, the optimal primary care strategy for managing patients with moderate-to-severe heartburn symptoms is to treat the symptoms with a {PPI} followed by maintenance therapy with an H2RA to prevent symptomatic recurrence.},
	pages = {312--328},
	number = {4},
	journaltitle = {Value in Health},
	shortjournal = {Value in Health},
	author = {Goeree, Ron and O'Brien, Bernie J. and Blackhouse, Gordon and Marshall, John and Briggs, Andrew and Lad, Rameeta},
	date = {2002-07-01},
	keywords = {cost-effectiveness analysis, cost-utility analysis, economic evaluation, heartburn},
}

@article{coello2005,
	title = {Adverse impact of surgical site infections in English hospitals},
	volume = {60},
	issn = {0195-6701},
	url = {https://www.sciencedirect.com/science/article/pii/S0195670104005183},
	doi = {10.1016/j.jhin.2004.10.019},
	abstract = {Summary
Between October 1997 and June 2001, 140 English hospitals participating in the surveillance of surgical site infection ({SSI}) with the Nosocomial Infection National Surveillance Service ({NINSS}) reported 2832 {SSIs} following 67 410 surgical procedures in nine defined categories of surgery. Limb amputation had the highest incidence of {SSI} with 14.3 {SSIs} per 100 operations. For all categories of surgery, except knee prosthesis (P=0.128), there was a linear increase in the incidence of {SSI} when the American National Nosocomial Infections Surveillance risk index increased. Superficial incisional {SSI} was more common than deep incisional and organ/space {SSI}, and accounted for more than half of all {SSIs} for all categories of surgery. The postoperative length of stay ({LOS}) was longer for patients with {SSI}, and when adjusted for other factors influencing {LOS}, the extra {LOS} due to {SSI} ranged from 3.3 days for abdominal hysterectomy to 21.0 days for limb amputation, and was at least nine days for the other categories. The additional cost attributable to {SSI} ranged from £959 for abdominal hysterectomy to £6103 for limb amputation. Deep incisional and organ/space {SSI} combined incurred a greater extra {LOS} and cost than superficial incisional {SSI} for all categories of surgery, except limb amputation. The crude mortality rate was higher for patients with {SSI} for all categories of surgery but, after controlling for confounding, only patients with {SSI} following hip prosthesis had a mortality rate that was significantly higher than those without {SSI} [odds ratio ({OR})=1.8, P=0.002]. However, the adjusted mortality rate for patients with deep incisional and organ/space {SSI} compared with those without {SSI} was significantly higher for vascular surgery ({OR}=6.8, P{\textless}0.001), hip prosthesis ({OR}=2.5, P=0.005) and large bowel surgery ({OR}=1.8, P=0.04). This study shows that the adverse impact of {SSI} differs greatly for different categories of surgery, and highlights the importance of measuring the impact for defined categories rather than for all {SSIs} and all surgical procedures.},
	pages = {93--103},
	number = {2},
	journaltitle = {Journal of Hospital Infection},
	shortjournal = {Journal of Hospital Infection},
	author = {Coello, R. and Charlett, A. and Wilson, J. and Ward, V. and Pearson, A. and Borriello, P.},
	date = {2005-06-01},
	keywords = {Cost, Length of hospital stay, Mortality, Surgical site infection},
}

@article{briggs2012a,
	title = {Model Parameter Estimation and Uncertainty: A Report of the {ISPOR}-{SMDM} Modeling Good Research Practices Task Force-6},
	volume = {15},
	issn = {1098-3015},
	url = {https://www.sciencedirect.com/science/article/pii/S1098301512016592},
	doi = {10.1016/j.jval.2012.04.014},
	abstract = {A model's purpose is to inform medical decisions and health care resource allocation. Modelers employ quantitative methods to structure the clinical, epidemiological, and economic evidence base and gain qualitative insight to assist decision makers in making better decisions. From a policy perspective, the value of a model-based analysis lies not simply in its ability to generate a precise point estimate for a specific outcome but also in the systematic examination and responsible reporting of uncertainty surrounding this outcome and the ultimate decision being addressed. Different concepts relating to uncertainty in decision modeling are explored. Stochastic (first-order) uncertainty is distinguished from both parameter (second-order) uncertainty and from heterogeneity, with structural uncertainty relating to the model itself forming another level of uncertainty to consider. The article argues that the estimation of point estimates and uncertainty in parameters is part of a single process and explores the link between parameter uncertainty through to decision uncertainty and the relationship to value of information analysis. The article also makes extensive recommendations around the reporting of uncertainty, in terms of both deterministic sensitivity analysis techniques and probabilistic methods. Expected value of perfect information is argued to be the most appropriate presentational technique, alongside cost-effectiveness acceptability curves, for representing decision uncertainty from probabilistic analysis.},
	pages = {835--842},
	number = {6},
	journaltitle = {Value in Health},
	shortjournal = {Value in Health},
	author = {Briggs, Andrew H. and Weinstein, Milton C. and Fenwick, Elisabeth A.L. and Karnon, Jonathan and Sculpher, Mark J. and Paltiel, A. David},
	date = {2012-09-01},
	keywords = {best practices, heterogeneity, sensitivity analysis, uncertainty analysis, value of information},
}

@book{briggs2006,
	location = {Oxford, {UK}},
	title = {Decision modelling for health economic evaluation},
	isbn = {978-0-19-852662-9},
	publisher = {Oxford University Press},
	author = {Briggs, Andrew and Claxton, Karl and Sculpher, Mark},
	date = {2006},
}

@article{leaper2017,
	title = {Meta-analysis of the potential economic impact following introduction of absorbable antimicrobial sutures},
	volume = {104},
	issn = {0007-1323},
	url = {https://doi.org/10.1002/bjs.10443},
	doi = {10.1002/bjs.10443},
	abstract = {Abstract Background Despite several randomized trials, systematic reviews and meta-analyses that have demonstrated the effectiveness of antimicrobial (triclosan-coated or -impregnated) sutures ({TCS}), the clinical and economic impact of using these sutures compared with conventional non-antimicrobial-coated absorbable sutures ({NCS}) remains poorly documented. Methods An independent systematic review and meta-analysis of all published evidence from January 2005 to September 2016 comparing {TCS} with {NCS} was conducted. Surgical-site infection ({SSI}) was the primary outcome. The results of the meta-analysis were used in a decision-tree deterministic and stochastic cost model, using the National Health Service ({NHS} England)-based cost of inpatient admissions for infections and differential costs of {TCS} versus {NCS}. Results Thirty-four studies were included in the final assessment from an initial 163 identified citations; 20 of 34 studies were randomized, and 17 of 34 reported blinding of physicians and assessors. Using a random-effects model, the odds ratio for {SSI} in the {TCS} compared with {NCS} control groups was statistically significant (odds ratio 0·61, 95 per cent c.i. 0·52 to 0·73; P {\textless} 0·001). There was significant heterogeneity (I2 = 49 per cent). Using random-effects event estimates of {SSI} for {TCS} and {NCS} for each individual wound type, the mean savings per surgical procedure from using antimicrobial sutures were significant: £91·25 (90 per cent c.i. 49·62 to 142·76) (?105·09 (57·15 to 164·41); exchange rate 15 November 2016) across all wound types. Conclusion The reviewed literature suggested that antimicrobial sutures may result in significant savings across various surgical wound types.},
	pages = {e134--e144},
	number = {2},
	journaltitle = {{BJS} (British Journal of Surgery)},
	shortjournal = {{BJS} (British Journal of Surgery)},
	author = {Leaper, D. J. and Edmiston Jr, C. E. and Holy, C. E.},
	urldate = {2021-02-04},
	date = {2017-01-01},
	note = {Publisher: John Wiley \& Sons, Ltd},
}

@article{jenks2017a,
	title = {Cost-utility analysis of the insufflation of warmed humidified carbon dioxide during open and laparoscopic colorectal surgery},
	volume = {17},
	issn = {1473-7167},
	url = {https://doi.org/10.1080/14737167.2017.1270759},
	doi = {10.1080/14737167.2017.1270759},
	pages = {99--107},
	number = {1},
	journaltitle = {Expert Review of Pharmacoeconomics \& Outcomes Research},
	shortjournal = {null},
	author = {Jenks, Michelle and Taylor, Matthew and Shore, Judith},
	date = {2017-01-02},
	note = {Publisher: Taylor \& Francis},
}

@report{swat2017,
	location = {{UK}},
	title = {Ontology and Knowledge Base of Probability Distributions},
	url = {https://sites.google.com/site/probonto/download},
	number = {{ProbOnto} 2.5},
	institution = {{EMBL}-{EBI}},
	type = {Technical Report},
	author = {Swat, Maciej J. and Grenon, Pierre and Wimalaratne, Sarala},
	date = {2017-01-13},
}

@article{bodycombe2020,
	title = {Burger run},
	volume = {246},
	pages = {54},
	number = {3285},
	journaltitle = {New Scientist},
	author = {Bodycombe, David},
	date = {2020-06-06},
}
