
@manual{allaire2020,
  type = {manual},
  title = {Rmarkdown: {{Dynamic}} Documents for r},
  author = {Allaire, JJ and Xie, Yihui and McPherson, Jonathan and Luraschi, Javier and Ushey, Kevin and Atkins, Aron and Wickham, Hadley and Cheng, Joe and Chang, Winston and Iannone, Richard},
  date = {2020},
  url = {https://github.com/rstudio/rmarkdown}
}

@article{beck1983,
  title = {The {{Markov Process}} in {{Medical Prognosis}}},
  author = {Beck, J.Robert and Pauker, Stephen G.},
  date = {1983-12-01},
  journaltitle = {Medical Decision Making},
  shortjournal = {Med Decis Making},
  volume = {3},
  number = {4},
  pages = {419--458},
  publisher = {{SAGE Publications Inc STM}},
  issn = {0272-989X},
  doi = {10.1177/0272989X8300300403},
  url = {https://doi.org/10.1177/0272989X8300300403},
  urldate = {2021-08-10},
  abstract = {The physician's estimate of prognosis under alternative treatment plans is a principal factor in therapeutic decision making. Current methods of reporting prognosis, which include five-year survivals, survival curves, and quality-adjusted life expec tancy, are crude estimates of natural history. In this paper we describe a general- purpose model of medical prognosis based on the Markov process and show how this simple mathematical tool may be used to generate detailed and accurate assessments of life expectancy and health status. (Med Decis Making 3:419-458, 1983)}
}

@article{bodycombe2020,
  title = {Burger Run},
  author = {Bodycombe, David},
  date = {2020-06-06},
  journaltitle = {New Scientist},
  volume = {246},
  number = {3285},
  pages = {54},
  entrysubtype = {magazine}
}

@book{briggs2006,
  title = {Decision Modelling for Health Economic Evaluation},
  author = {Briggs, Andrew and Claxton, Karl and Sculpher, Mark},
  date = {2006},
  publisher = {{Oxford University Press}},
  location = {{Oxford, UK}},
  isbn = {978-0-19-852662-9}
}

@article{briggs2012a,
  title = {Model {{Parameter Estimation}} and {{Uncertainty}}: {{A Report}} of the {{ISPOR}}-{{SMDM Modeling Good Research Practices Task Force}}-6},
  author = {Briggs, Andrew H. and Weinstein, Milton C. and Fenwick, Elisabeth A.L. and Karnon, Jonathan and Sculpher, Mark J. and Paltiel, A. David},
  date = {2012-09-01},
  journaltitle = {Value in Health},
  shortjournal = {Value in Health},
  volume = {15},
  number = {6},
  pages = {835--842},
  issn = {1098-3015},
  doi = {10.1016/j.jval.2012.04.014},
  url = {https://www.sciencedirect.com/science/article/pii/S1098301512016592},
  abstract = {A model's purpose is to inform medical decisions and health care resource allocation. Modelers employ quantitative methods to structure the clinical, epidemiological, and economic evidence base and gain qualitative insight to assist decision makers in making better decisions. From a policy perspective, the value of a model-based analysis lies not simply in its ability to generate a precise point estimate for a specific outcome but also in the systematic examination and responsible reporting of uncertainty surrounding this outcome and the ultimate decision being addressed. Different concepts relating to uncertainty in decision modeling are explored. Stochastic (first-order) uncertainty is distinguished from both parameter (second-order) uncertainty and from heterogeneity, with structural uncertainty relating to the model itself forming another level of uncertainty to consider. The article argues that the estimation of point estimates and uncertainty in parameters is part of a single process and explores the link between parameter uncertainty through to decision uncertainty and the relationship to value of information analysis. The article also makes extensive recommendations around the reporting of uncertainty, in terms of both deterministic sensitivity analysis techniques and probabilistic methods. Expected value of perfect information is argued to be the most appropriate presentational technique, alongside cost-effectiveness acceptability curves, for representing decision uncertainty from probabilistic analysis.},
  keywords = {best practices,heterogeneity,sensitivity analysis,uncertainty analysis,value of information}
}

@article{chancellor1997,
  title = {Modelling the Cost Effectiveness of {{Lamivudine}}/{{Zidovudine}} Combination Therapy in {{HIV}} Infection},
  author = {Chancellor, Jeremy V. and Hill, Andrew M. and Sabin, Caroline A. and Simpson, Kit N. and Youle, Mike},
  date = {1997},
  journaltitle = {Pharmacoeconomics},
  volume = {12},
  number = {1},
  pages = {54--66}
}

@manual{chang2020,
  type = {manual},
  title = {R6: {{Encapsulated}} Classes with Reference Semantics},
  author = {Chang, Winston},
  date = {2020},
  url = {https://CRAN.R-project.org/package=R6}
}

@article{coello2005,
  title = {Adverse Impact of Surgical Site Infections in {{English}} Hospitals},
  author = {Coello, R. and Charlett, A. and Wilson, J. and Ward, V. and Pearson, A. and Borriello, P.},
  date = {2005-06-01},
  journaltitle = {Journal of Hospital Infection},
  shortjournal = {Journal of Hospital Infection},
  volume = {60},
  number = {2},
  pages = {93--103},
  issn = {0195-6701},
  doi = {10.1016/j.jhin.2004.10.019},
  url = {https://www.sciencedirect.com/science/article/pii/S0195670104005183},
  abstract = {Summary Between October 1997 and June 2001, 140 English hospitals participating in the surveillance of surgical site infection (SSI) with the Nosocomial Infection National Surveillance Service (NINSS) reported 2832 SSIs following 67\hphantom{,}410 surgical procedures in nine defined categories of surgery. Limb amputation had the highest incidence of SSI with 14.3 SSIs per 100 operations. For all categories of surgery, except knee prosthesis (P=0.128), there was a linear increase in the incidence of SSI when the American National Nosocomial Infections Surveillance risk index increased. Superficial incisional SSI was more common than deep incisional and organ/space SSI, and accounted for more than half of all SSIs for all categories of surgery. The postoperative length of stay (LOS) was longer for patients with SSI, and when adjusted for other factors influencing LOS, the extra LOS due to SSI ranged from 3.3 days for abdominal hysterectomy to 21.0 days for limb amputation, and was at least nine days for the other categories. The additional cost attributable to SSI ranged from \textsterling 959 for abdominal hysterectomy to \textsterling 6103 for limb amputation. Deep incisional and organ/space SSI combined incurred a greater extra LOS and cost than superficial incisional SSI for all categories of surgery, except limb amputation. The crude mortality rate was higher for patients with SSI for all categories of surgery but, after controlling for confounding, only patients with SSI following hip prosthesis had a mortality rate that was significantly higher than those without SSI [odds ratio (OR)=1.8, P=0.002]. However, the adjusted mortality rate for patients with deep incisional and organ/space SSI compared with those without SSI was significantly higher for vascular surgery (OR=6.8, P{$<$}0.001), hip prosthesis (OR=2.5, P=0.005) and large bowel surgery (OR=1.8, P=0.04). This study shows that the adverse impact of SSI differs greatly for different categories of surgery, and highlights the importance of measuring the impact for defined categories rather than for all SSIs and all surgical procedures.},
  keywords = {Cost,Length of hospital stay,Mortality,Surgical site infection}
}

@article{dong2006,
  title = {Early Assessment of the Likely Cost-Effectiveness of a New Technology: {{A Markov}} Model with Probabilistic Sensitivity Analysis of Computer-Assisted Total Knee Replacement},
  author = {Dong, Hengjin and Buxton, Martin},
  date = {2006},
  journaltitle = {International Journal of Technology Assessment in Health Care},
  edition = {2006/03/28},
  volume = {22},
  number = {2},
  pages = {191--202},
  publisher = {{Cambridge University Press}},
  issn = {0266-4623},
  doi = {10.1017/S0266462306051014},
  url = {https://www.cambridge.org/core/article/early-assessment-of-the-likely-costeffectiveness-of-a-new-technology-a-markov-model-with-probabilistic-sensitivity-analysis-of-computerassisted-total-knee-replacement/2B99B141DDBD3F58FBD57F90425CA23B},
  abstract = {Objectives: The objective of this study is to apply a Markov model to compare cost-effectiveness of total knee replacement (TKR) using computer-assisted surgery (CAS) with that of TKR using a conventional manual method in the absence of formal clinical trial evidence.Methods: A structured search was carried out to identify evidence relating to the clinical outcome, cost, and effectiveness of TKR. Nine Markov states were identified based on the progress of the disease after TKR. Effectiveness was expressed by quality-adjusted life years (QALYs). The simulation was carried out initially for 120 cycles of a month each, starting with 1,000 TKRs. A discount rate of 3.5 percent was used for both cost and effectiveness in the incremental cost-effectiveness analysis. Then, a probabilistic sensitivity analysis was carried out using a Monte Carlo approach with 10,000 iterations.Results: Computer-assisted TKR was a long-term cost-effective technology, but the QALYs gained were small. After the first 2 years, the incremental cost per QALY of computer-assisted TKR was dominant because of cheaper and more QALYs. The incremental cost-effectiveness ratio (ICER) was sensitive to the ``effect of CAS,'' to the CAS extra cost, and to the utility of the state ``Normal health after primary TKR,'' but it was not sensitive to utilities of other Markov states. Both probabilistic and deterministic analyses produced similar cumulative serious or minor complication rates and complex or simple revision rates. They also produced similar ICERs.Conclusions: Compared with conventional TKR, computer-assisted TKR is a cost-saving technology in the long-term and may offer small additional QALYs. The ``effect of CAS'' is to reduce revision rates and complications through more accurate and precise alignment, and although the conclusions from the model, even when allowing for a full probabilistic analysis of uncertainty, are clear, the ``effect of CAS'' on the rate of revisions awaits long-term clinical evidence.},
  keywords = {Computer-assisted surgery,Cost-effectiveness analysis,Incremental cost-effectiveness ratio,Markov model,QALY,Total knee replacement}
}

@article{evans1997,
  title = {Economic Evaluation of Oral {{Sumatriptan}} Compared with Oral {{Caffeine}}/{{Ergotamine}} for Migraine},
  author = {Evans, Kenneth W. and Boan, John A. and Evans, John L. and Shuaib, Ashfaq},
  date = {1997},
  journaltitle = {Pharmacoeconomics},
  volume = {12},
  number = {5},
  pages = {565--577}
}

@article{fleurence2007,
  title = {Rates and {{Probabilities}} in {{Economic Modelling}}},
  author = {Fleurence, Rachael L. and Hollenbeak, Christopher S.},
  date = {2007-01-01},
  journaltitle = {PharmacoEconomics},
  shortjournal = {PharmacoEconomics},
  volume = {25},
  number = {1},
  pages = {3--6},
  issn = {1179-2027},
  doi = {10.2165/00019053-200725010-00002},
  url = {https://doi.org/10.2165/00019053-200725010-00002},
  abstract = {Economic modelling is increasingly being used to evaluate the cost effectiveness of health technologies. One of the requirements for good practice in modelling is appropriate application of rates and probabilities. In spite of previous descriptions of appropriate use of rates and probabilities, confusions persist beyond a simple understanding of their definitions. The objective of this article is to provide a concise guide to understanding the issues surrounding the use of rates and probabilities reported in the literature in economic models, and an understanding of when and how to transform them appropriately. The article begins by defining rates and probabilities and shows the essential difference between the two measures. Appropriate conversions between rates and probabilities are discussed, and simple examples are provided to illustrate the techniques and pitfalls. How the transformed rates and probabilities may be used in economic models is then described and some recommendations are suggested.}
}

@article{gansner1993,
  title = {A Technique for Drawing Directed Graphs},
  author = {Gansner, E. R. and Koutsofios, E. and North, S. C. and Vo, K-P.},
  date = {1993-03},
  journaltitle = {IEEE Transactions on Software Engineering},
  shortjournal = {IEEE Transactions on Software Engineering},
  volume = {19},
  number = {3},
  pages = {214--230},
  issn = {1939-3520},
  doi = {10.1109/32.221135},
  abstract = {A four-pass algorithm for drawing directed graphs is presented. The fist pass finds an optimal rank assignment using a network simplex algorithm. The seconds pass sets the vertex order within ranks by an iterative heuristic, incorporating a novel weight function and local transpositions to reduce crossings. The third pass finds optimal coordinates for nodes by constructing and ranking an auxiliary graph. The fourth pass makes splines to draw edges. The algorithm creates good drawings and is fast.}
}

@article{goeree1999,
  title = {Economic {{Evaluation}} of {{Long Term Management Strategies}} for {{Erosive Oesophagitis}}},
  author = {Goeree, Ron and O'Brien, Bernie and Hunt, Richard and Blackhouse, Gordon and Willan, Andrew and Watson, Jan},
  date = {1999-12-01},
  journaltitle = {PharmacoEconomics},
  shortjournal = {PharmacoEconomics},
  volume = {16},
  number = {6},
  pages = {679--697},
  issn = {1179-2027},
  doi = {10.2165/00019053-199916060-00007},
  url = {https://doi.org/10.2165/00019053-199916060-00007},
  abstract = {Objective: To compare the expected costs and outcomes of alternative strategies for the management of patients with erosive oesophagitis.}
}

@article{goeree2002,
  title = {Cost-{{Effectiveness}} and {{Cost}}-{{Utility}} of {{Long}}-{{Term Management Strategies}} for {{Heartburn}}},
  author = {Goeree, Ron and O'Brien, Bernie J. and Blackhouse, Gordon and Marshall, John and Briggs, Andrew and Lad, Rameeta},
  date = {2002-07-01},
  journaltitle = {Value in Health},
  shortjournal = {Value in Health},
  volume = {5},
  number = {4},
  pages = {312--328},
  issn = {1098-3015},
  doi = {10.1046/j.1524-4733.2002.54145.x},
  url = {http://www.sciencedirect.com/science/article/pii/S1098301510600228},
  abstract = {Objectives To compare the expected costs and outcomes of seven alternative long-term primary care strategies for the management of patients with moderate-to-severe heartburn over a 1-year period. Methods A decision-analytic model was developed to estimate costs and effects (weeks with heartburn symptoms and quality adjusted life years QALYs]) for each strategy. Meta-analyses were used to synthesize acute treatment and maintenance studies and physician surveys to collect information on patient management. The impact of uncertainty on the base case results was assessed using probabilistic sensitivity analysis. Probability distributions were defined for key model parameters and techniques of Monte Carlo simulation were used to draw values from these distributions. Cost-effectiveness acceptability curves (CEACs) conditional on the monetary value decision makers are willing to pay for a symptom-free day or QALY were created for each strategy. Results In the base case, no strategy was strictly dominated by any other strategy. However, two strategies (maintenance H2-receptor antagonists H2RA] and step-down proton pump inhibitor PPI]) were dominated through principles of extended dominance. The least costly and least effective strategy was intermittent H2RA, while maintenance PPI was the most costly and most effective. Conclusions This analysis showed that the best way of managing patients with heartburn depends on how much society is willing to pay to achieve health improvements. Based on the commonly quoted threshold of \$50,000 per QALY, the optimal primary care strategy for managing patients with moderate-to-severe heartburn symptoms is to treat the symptoms with a PPI followed by maintenance therapy with an H2RA to prevent symptomatic recurrence.},
  keywords = {cost-effectiveness analysis,cost-utility analysis,economic evaluation,heartburn}
}

@manual{goulet2021,
  type = {manual},
  title = {Expm: {{Matrix}} Exponential, Log, Etc},
  author = {Goulet, Vincent and Dutang, Christophe and Maechler, Martin and Firth, David and Shapira, Marina and Stadelmann, Michael},
  date = {2021},
  url = {https://CRAN.R-project.org/package=expm}
}

@article{grill2005,
  title = {Comparing the Clinical Effectiveness of Different New-Born Hearing Screening Strategies. {{A}} Decision Analysis},
  author = {Grill, Eva and Hessel, Franz and Siebert, Uwe and Schnell-Inderst, Petra and Kunze, Silke and Nickisch, Andreas and Wasem, J\"urgen},
  date = {2005-01-31},
  journaltitle = {BMC Public Health},
  shortjournal = {BMC Public Health},
  volume = {5},
  number = {1},
  pages = {12},
  issn = {1471-2458},
  doi = {10.1186/1471-2458-5-12},
  url = {https://doi.org/10.1186/1471-2458-5-12},
  abstract = {Children with congenital hearing impairment benefit from early detection and treatment. At present, no model exists which explicitly quantifies the effectiveness of universal newborn hearing screening (UNHS) versus other programme alternatives in terms of early diagnosis. It has yet to be considered whether early diagnosis (within the first few months) of hearing impairment is of importance with regard to the further development of the child compared with effects resulting from a later diagnosis. The objective was to systematically compare two screening strategies for the early detection of new-born hearing disorders, UNHS and risk factor screening, with no systematic screening regarding their influence on early diagnosis.}
}

@book{gross2013,
  title = {Handbook of {{Graph Theory}}},
  author = {Gross, J. L. and Yellen, J. and Zhang, P.},
  date = {2013},
  edition = {2},
  publisher = {{Chapman and Hall/CRC.}},
  url = {https://doi.org/10.1201/b16132},
  isbn = {978-0-429-19275-3},
  pagetotal = {1630}
}

@manual{henry2020,
  type = {manual},
  title = {Rlang: {{Functions}} for Base Types and Core r and 'tidyverse' Features},
  author = {Henry, Lionel and Wickham, Hadley},
  date = {2020},
  url = {https://CRAN.R-project.org/package=rlang}
}

@article{jenks2016,
  ids = {jenks2016a},
  title = {Tegaderm {{CHG IV Securement Dressing}} for {{Central Venous}} and {{Arterial Catheter Insertion Sites}}: {{A NICE Medical Technology Guidance}}},
  author = {Jenks, Michelle and Craig, Joyce and Green, William and Hewitt, Neil and Arber, Mick and Sims, Andrew J},
  date = {2016-04},
  journaltitle = {Applied Health Economics and Health Policy},
  volume = {14},
  number = {2},
  pages = {135--149},
  publisher = {{Springer International Publishing}},
  issn = {1175-5652},
  doi = {10.1007/s40258-015-0202-5},
  url = {http://link.springer.com/10.1007/s40258-015-0202-5}
}

@article{jenks2017a,
  title = {Cost-Utility Analysis of the Insufflation of Warmed Humidified Carbon Dioxide during Open and Laparoscopic Colorectal Surgery},
  author = {Jenks, Michelle and Taylor, Matthew and Shore, Judith},
  date = {2017-01-02},
  journaltitle = {Expert Review of Pharmacoeconomics \& Outcomes Research},
  shortjournal = {null},
  volume = {17},
  number = {1},
  pages = {99--107},
  publisher = {{Taylor \& Francis}},
  issn = {1473-7167},
  doi = {10.1080/14737167.2017.1270759},
  url = {https://doi.org/10.1080/14737167.2017.1270759}
}

@article{jones2017,
  title = {A {{Procedure}} for {{Deriving Formulas}} to {{Convert Transition Rates}} to {{Probabilities}} for {{Multistate Markov Models}}},
  author = {Jones, Edmund and Epstein, David and Garc\'ia-Moch\'on, Leticia},
  date = {2017-10-01},
  journaltitle = {Medical Decision Making},
  shortjournal = {Med Decis Making},
  volume = {37},
  number = {7},
  pages = {779--789},
  publisher = {{SAGE Publications Inc STM}},
  issn = {0272-989X},
  doi = {10.1177/0272989X17696997},
  url = {https://doi.org/10.1177/0272989X17696997},
  urldate = {2021-08-13},
  abstract = {For health-economic analyses that use multistate Markov models, it is often necessary to convert from transition rates to transition probabilities, and for probabilistic sensitivity analysis and other purposes it is useful to have explicit algebraic formulas for these conversions, to avoid having to resort to numerical methods. However, if there are four or more states then the formulas can be extremely complicated. These calculations can be made using packages such as R, but many analysts and other stakeholders still prefer to use spreadsheets for these decision models. We describe a procedure for deriving formulas that use intermediate variables so that each individual formula is reasonably simple. Once the formulas have been derived, the calculations can be performed in Excel or similar software. The procedure is illustrated by several examples and we discuss how to use a computer algebra system to assist with it. The procedure works in a wide variety of scenarios but cannot be employed when there are several backward transitions and the characteristic equation has no algebraic solution, or when the eigenvalues of the transition rate matrix are very close to each other.}
}

@article{kahn1962,
  title = {Topological Sorting of Large Networks},
  author = {Kahn, A. B.},
  date = {1962-11},
  journaltitle = {Communications of the ACM},
  volume = {5},
  number = {11},
  pages = {558--562},
  publisher = {{Association for Computing Machinery}},
  address = {New York, NY, USA},
  issn = {0001-0782},
  doi = {10.1145/368996.369025},
  url = {https://doi.org/10.1145/368996.369025},
  abstract = {Topological Sorting is a procedure required for many problems involving analysis of networks. An example of one such problem is PERT. The present paper presents a very general method for obtaining topological order. It permits treatment of larger networks than can be handled on present procedures and achieves this with greater efficiency. Although the procedure can be adapted to any machine, it is discussed in terms of the 7090. A PERT network of 30,000 activities can be ordered in less than one hour of machine time. The method was developed as a byproduct of procedure needed by Westinghouse, Baltimore. It has not been programmed and at present there are no plans to implement it. In regard to the techniques described, Westinghouse's present and anticipated needs are completely served by the Lockheed program, which is in current use.},
  issue_date = {Nov. 1962},
  pagetotal = {5}
}

@article{kaminski2018,
  title = {A Framework for Sensitivity Analysis of Decision Trees},
  author = {Kami\'nski, Bogumil and Jakubczyk, Michal and Szufel, Przemyslaw},
  date = {2018},
  journaltitle = {Central European Journal of Operational Research},
  volume = {26},
  pages = {135--159},
  doi = {10.1007/s10100-017-0479-6}
}

@article{leaper2017,
  title = {Meta-Analysis of the Potential Economic Impact Following Introduction of Absorbable Antimicrobial Sutures},
  author = {Leaper, D. J. and Edmiston Jr, C. E. and Holy, C. E.},
  date = {2017-01-01},
  journaltitle = {BJS (British Journal of Surgery)},
  shortjournal = {BJS (British Journal of Surgery)},
  volume = {104},
  number = {2},
  pages = {e134-e144},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {0007-1323},
  doi = {10.1002/bjs.10443},
  url = {https://doi.org/10.1002/bjs.10443},
  urldate = {2021-02-04},
  abstract = {Abstract Background Despite several randomized trials, systematic reviews and meta-analyses that have demonstrated the effectiveness of antimicrobial (triclosan-coated or -impregnated) sutures (TCS), the clinical and economic impact of using these sutures compared with conventional non-antimicrobial-coated absorbable sutures (NCS) remains poorly documented. Methods An independent systematic review and meta-analysis of all published evidence from January 2005 to September 2016 comparing TCS with NCS was conducted. Surgical-site infection (SSI) was the primary outcome. The results of the meta-analysis were used in a decision-tree deterministic and stochastic cost model, using the National Health Service (NHS England)-based cost of inpatient admissions for infections and differential costs of TCS versus NCS. Results Thirty-four studies were included in the final assessment from an initial 163 identified citations; 20 of 34 studies were randomized, and 17 of 34 reported blinding of physicians and assessors. Using a random-effects model, the odds ratio for SSI in the TCS compared with NCS control groups was statistically significant (odds ratio 0{$\cdot$}61, 95 per cent c.i. 0{$\cdot$}52 to 0{$\cdot$}73; P {$<$} 0{$\cdot$}001). There was significant heterogeneity (I2 = 49 per cent). Using random-effects event estimates of SSI for TCS and NCS for each individual wound type, the mean savings per surgical procedure from using antimicrobial sutures were significant: \textsterling 91{$\cdot$}25 (90 per cent c.i. 49{$\cdot$}62 to 142{$\cdot$}76) (?105{$\cdot$}09 (57{$\cdot$}15 to 164{$\cdot$}41); exchange rate 15 November 2016) across all wound types. Conclusion The reviewed literature suggested that antimicrobial sutures may result in significant savings across various surgical wound types.}
}

@article{miller1994,
  title = {Determining {{Transition Probabilities}}: {{Confusion}} and {{Suggestions}}},
  author = {Miller, Douglas K. and Homan, Sharon M.},
  date = {1994-02-01},
  journaltitle = {Medical Decision Making},
  shortjournal = {Med Decis Making},
  volume = {14},
  number = {1},
  pages = {52--58},
  publisher = {{SAGE Publications Inc STM}},
  issn = {0272-989X},
  doi = {10.1177/0272989X9401400107},
  url = {https://doi.org/10.1177/0272989X9401400107},
  urldate = {2021-08-10},
  abstract = {Confusion regarding proper use of the terms rate and risk persists in the literature. This has implications for the proper modeling of prognosis and transition between health states in decision analysis and related techniques. The issue is complicated by the plethora of terms related to rate and risk. Although the suggestion to use the terms force and probability as substitutes for rate and risk has some appeal, the change in terminology by itself is unlikely to solve all the confusion or misuse of terms. This paper clarifies the proper definitions and estimations of rates and risks and suggests critical factors for the decision analyst to re member when using, modeling, or interpreting transition rates and risks. Key words: decision models; rate; risk; force; probability; transitions. (Med Decis Making 1994;14:52-58)}
}

@report{NICE2020a,
  type = {Medtech innovation briefing},
  title = {Plus {{Sutures}} for Preventing Surgical Site Infection},
  author = {{NICE}},
  date = {2020-02-04},
  number = {MIB 204},
  institution = {{National Institute for Health and Care Excellence}},
  url = {https://www.nice.org.uk/guidance/mib204},
  isbn = {978-1-4731-3675-5}
}

@article{petrou2011,
  title = {Economic Evaluation Using Decision Analytical Modelling: Design, Conduct, Analysis, and Reporting},
  author = {Petrou, Stavros and Gray, Alastair},
  date = {2011-04-11},
  journaltitle = {BMJ},
  shortjournal = {BMJ},
  volume = {342},
  pages = {d1766},
  doi = {10.1136/bmj.d1766},
  url = {http://www.bmj.com/content/342/bmj.d1766.abstract},
  abstract = {Evidence relating to healthcare decisions often comes from more than one study. Decision analytical modelling can be used as a basis for economic evaluations in these situations.Economic evaluations are increasingly conducted alongside randomised controlled trials, providing researchers with individual patient data to estimate cost effectiveness.1 However, randomised trials do not always provide a sufficient basis for economic evaluations used to inform regulatory and reimbursement decisions. For example, a single trial might not compare all the available options, provide evidence on all relevant inputs, or be conducted over a long enough time to capture differences in economic outcomes (or even measure those outcomes).2 In addition, reliance on a single trial may mean ignoring evidence from other trials, meta-analyses, and observational studies. Under these circumstances, decision analytical modelling provides an alternative framework for economic evaluation.Decision analytical modelling compares the expected costs and consequences of decision options by synthesising information from multiple sources and applying mathematical techniques, usually with computer software. The aim is to provide decision makers with the best available evidence to reach a decision\textemdash for example, should a new drug be adopted? Following on from our article on trial based economic evaluations,1 we outline issues relating to the design, conduct, analysis, and reporting of economic evaluations using decision analytical modelling. Glossary of termsCost effectiveness acceptability curve\textemdash Graphical depiction of the probability that a health intervention is cost effective across a range of willingness to pay thresholds held by decision makers for the health outcome of interestCost effectiveness plane\textemdash Graphical depiction of difference in effectiveness between the new treatment and the comparator against the difference in costDiscounting\textemdash The practice of reducing future costs and health outcomes to present values Health utilities\textemdash Preference based outcomes normally represented on a scale where 0 represents death and 1 represents perfect \ldots}
}

@manual{rcoreteam2020,
  type = {manual},
  title = {R: {{A}} Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  date = {2020},
  location = {{Vienna, Austria}},
  url = {https://www.R-project.org/},
  organization = {{R Foundation for Statistical Computing}}
}

@article{siebert2012,
  title = {State-{{Transition Modeling}}: {{A Report}} of the {{ISPOR}}-{{SMDM Modeling Good Research Practices Task Force}}-3},
  author = {Siebert, Uwe and Alagoz, Oguzhan and Bayoumi, Ahmed M. and Jahn, Beate and Owens, Douglas K. and Cohen, David J. and Kuntz, Karen M.},
  date = {2012-09-01},
  journaltitle = {Value in Health},
  shortjournal = {Value in Health},
  volume = {15},
  number = {6},
  pages = {812--820},
  issn = {1098-3015},
  doi = {10.1016/j.jval.2012.06.014},
  url = {https://www.sciencedirect.com/science/article/pii/S1098301512016543},
  abstract = {State-transition modeling is an intuitive, flexible, and transparent approach of computer-based decision-analytic modeling including both Markov model cohort simulation and individual-based (first-order Monte Carlo) microsimulation. Conceptualizing a decision problem in terms of a set of (health) states and transitions among these states, state-transition modeling is one of the most widespread modeling techniques in clinical decision analysis, health technology assessment, and health-economic evaluation. State-transition models have been used in many different populations and diseases, and their applications range from personalized health care strategies to public health programs. Most frequently, state-transition models are used in the evaluation of risk factor interventions, screening, diagnostic procedures, treatment strategies, and disease management programs. The goal of this article was to provide consensus-based guidelines for the application of state-transition models in the context of health care. We structured the best practice recommendations in the following sections: choice of model type (cohort vs. individual-level model), model structure, model parameters, analysis, reporting, and communication. In each of these sections, we give a brief description, address the issues that are of particular relevance to the application of state-transition models, give specific examples from the literature, and provide best practice recommendations for state-transition modeling. These recommendations are directed both to modelers and to users of modeling results such as clinicians, clinical guideline developers, manufacturers, or policymakers.},
  keywords = {decision-analytic modeling,guidelines,Markov models,state-transition modeling}
}

@article{sonnenberg1993,
  ids = {sonnenberg1993a,sonnenberg:1993a},
  title = {Markov {{Models}} in {{Medical Decision Making}}: {{A Practical Guide}}},
  author = {Sonnenberg, F. A. and Beck, J. R.},
  date = {1993},
  journaltitle = {Medical Decision Making},
  volume = {13},
  number = {4},
  pages = {322--338},
  issn = {0272-989X},
  doi = {10.1177/0272989X9301300409},
  url = {http://mdm.sagepub.com/cgi/doi/10.1177/0272989X9301300409}
}

@report{swat2017,
  type = {Technical Report},
  title = {Ontology and {{Knowledge Base}} of {{Probability Distributions}}},
  author = {Swat, Maciej J. and Grenon, Pierre and Wimalaratne, Sarala},
  date = {2017-01-13},
  series = {Drug {{Disease Model Resources}}},
  number = {ProbOnto 2.5},
  institution = {{EMBL-EBI}},
  location = {{UK}},
  url = {https://sites.google.com/site/probonto/download}
}

@article{tilford1981,
  title = {Tidier {{Drawings}} of {{Trees}}},
  author = {Tilford, J. and Reingold, E.},
  date = {1981-03},
  journaltitle = {IEEE Transactions on Software Engineering},
  shortjournal = {IEEE Transactions on Software Engineering},
  volume = {7},
  number = {02},
  pages = {223--228},
  issn = {1939-3520},
  doi = {10.1109/TSE.1981.234519},
  url = {http://doi.ieeecomputersociety.org/10.1109/TSE.1981.234519},
  keywords = {Data Structures,Tree Structures,Trees}
}

@article{tirschwell2018,
  title = {Cost-Effectiveness of Percutaneous Patent Foramen Ovale Closure as Secondary Stroke Prevention},
  author = {Tirschwell, David L. and Turner, Mark and Thaler, David and Choulerton, James and Marks, David and Carroll, John and MacDonald, Lee and Smalling, Richard W. and Koullick, Maria and Gu, Ning Yan and Saver, Jeffrey L.},
  date = {2018-07-03},
  journaltitle = {Journal of Medical Economics},
  shortjournal = {null},
  volume = {21},
  number = {7},
  pages = {656--665},
  publisher = {{Taylor \& Francis}},
  issn = {1369-6998},
  doi = {10.1080/13696998.2018.1456445},
  url = {https://doi.org/10.1080/13696998.2018.1456445}
}

@report{walker1989,
  type = {Technical Report},
  title = {A Node-Positioning Algorithm for General Trees},
  author = {Walker, John Q.},
  date = {1989-09},
  number = {TR 89-034},
  institution = {{University of North Carolina}},
  location = {{Chapel Hill}},
  url = {http://www.cs.unc.edu/techreports/89-034.pdf},
  abstract = {Drawing a tree consists of two stages: determining the position of each node, and actually rendering the individuals nodes and interconnecting branches. The algorithm described in this paper is concerned with the first stage: given a list of nodes. an indication of the hierarchical relationship among them. and their shape and size, wrere should each node be positioned for optimal aesthetic effect? This algorithm determines the positions of the nodes for any arbitrary general tree. It is the most desirable positioning with respect to certain widely- accepted heuristics. The positioning, specified in x, y coordinates, minimizes the width of the tree. In a general tree, there is no limit on the number of off- spring per node; this contrasts with binary and ternary trees, for example, which are trees with a limit of 2 and 3 offspring per node. This algorithm oper- ates in time O(N), where N is the number of nodes in the tree. Previously, most tree drawings have been positioned by the sure hand of a human graphic designer. Many computer-generated positionings have been either trivial or contained irregularities. Earlier work by Wetherell and Shannon (1979) and Tilford (1981), upon which this algorithm builds, failed to correctly position the interior nodes of some trees. Radack (1988), also building on Tilford's work, has solved this same problem with a different method which makes four passes. The algorithm presented here correctly positions a tree's nodes using only two passes. It also handles several practical considerations: alternate orientations of the tree, variable node sizes, and out-of-bounds conditions.}
}

@article{welton2005,
  title = {Estimation of {{Markov Chain Transition Probabilities}} and {{Rates}} from {{Fully}} and {{Partially Observed Data}}: {{Uncertainty Propagation}}, {{Evidence Synthesis}}, and {{Model Calibration}}},
  author = {Welton, Nicky J. and Ades, A. E.},
  date = {2005-11-01},
  journaltitle = {Medical Decision Making},
  shortjournal = {Med Decis Making},
  volume = {25},
  number = {6},
  pages = {633--645},
  publisher = {{SAGE Publications Inc STM}},
  issn = {0272-989X},
  doi = {10.1177/0272989X05282637},
  url = {https://doi.org/10.1177/0272989X05282637},
  urldate = {2021-08-18},
  abstract = {Markov transition models are frequently used to model disease progression. The authors show how the solution to Kolmogorov?s forward equations can be exploited to map between transition rates and probabilities from probability data in multistate models. They provide a uniform, Bayesian treatment of estimation and propagation of uncertainty of transition rates and probabilities when 1) observations are available on all transitions and exact time at risk in each state (fully observed data) and 2) observations are on initial state and final state after a fixed interval of time but not on the sequence of transitions (partially observed data). The authors show how underlying transition rates can be recovered from partially observed data using Markov chain Monte Carlo methods in WinBUGS, and they suggest diagnostics to investigate inconsistencies between evidence from different starting states. An illustrative example for a 3-state model is given, which shows how the methods extend to more complex Markov models using the software WBDiff to compute solutions. Finally, the authors illustrate how to statistically combine data from multiple sources, including partially observed data at several follow-up times and also how to calibrate a Markov model to be consistent with data from one specific study.}
}

@article{wickham2011,
  title = {Testthat: {{Get}} Started with Testing},
  author = {Wickham, Hadley},
  date = {2011},
  journaltitle = {The R Journal},
  volume = {3},
  pages = {5--10},
  url = {https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf}
}

@manual{wickham2020,
  type = {manual},
  title = {Devtools: {{Tools}} to Make Developing r Packages Easier},
  author = {Wickham, Hadley and Hester, Jim and Chang, Winston},
  date = {2020},
  url = {https://CRAN.R-project.org/package=devtools}
}

@inreference{wikipedia2021,
  title = {Glossary of Graph Theory},
  booktitle = {Wikipedia},
  author = {{Wikipedia}},
  date = {2021},
  url = {https://en.wikipedia.org/wiki/Glossary_of_graph_theory}
}

@report{willits2012a,
  type = {NICE External Assessment Centre Report},
  title = {Cost Impact of the {{WatchBP Home A}} Used in a Primary Healthcare Clinic Environment},
  author = {Willits, I. and Keltie, Kim and Craig, Joyce and Sims, Andrew J.},
  date = {2012-08},
  institution = {{National Institute for Health and Care Excellence}},
  url = {https://www.nice.org.uk/guidance/MTG13}
}

@article{willits2014a,
  ids = {willits2014b},
  title = {{{WatchBP Home A}} for {{Opportunistically Detecting Atrial Fibrillation During Diagnosis}} and {{Monitoring}} of {{Hypertension}}: {{A NICE Medical Technology Guidance}}},
  author = {Willits, Iain and Keltie, Kim and Craig, Joyce and Sims, Andrew},
  date = {2014-06},
  journaltitle = {Applied Health Economics and Health Policy},
  volume = {12},
  number = {3},
  eprint = {24664995},
  eprinttype = {pmid},
  pages = {255--265},
  issn = {1175-5652},
  doi = {10.1007/s40258-014-0096-7},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/24664995 http://link.springer.com/10.1007/s40258-014-0096-7},
  abstract = {The Microlife(\textregistered ) 'WatchBP Home A' oscillometric blood pressure monitor detects irregular pulse, suggestive of atrial fibrillation (AF). Early detection of AF can prevent thromboembolic stroke via anticoagulation therapy. The device was considered by the Medical Technologies Evaluation Programme of the UK National Institute for Health and Care Excellence (NICE). The sponsor (Microlife) identified 10 studies. These were reviewed by an External Assessment Centre (EAC) which considered three relevant to the decision problem, including one which found the device detected AF more accurately (sensitivity 96.8 \%, specificity 88.8 \%) than pulse palpation (87.2, 81.3 \%). The EAC concluded the technology had potential to improve detection of AF, but the three studies had uncertain external validity. From a cost-consequence model with a 1-year timeframe, the sponsor calculated the device would reduce electrocardiogram (ECG) referrals and prevent strokes, but incur anticoagulation therapy costs, with net NHS savings of \textbackslash pounds11.6 million and prevention of 221 strokes, annually. The EAC criticised the model for its limited time horizon, and its consideration of symptomatic AF patients who were outside the scope issued by NICE. The EAC applied a de novo Markov model, with a 10-year timeframe. The per use saving was calculated as \textbackslash pounds2.98 for asymptomatic patients aged 65-74 years and \textbackslash pounds4.26 for those aged 75-84 years, with the prevention of 53-117 nonfatal and 28-65 fatal strokes per 100,000 people screened. Following consideration by the NICE Medical Technologies Advisory Committee, NICE judged that the case for adoption was supported by the evidence (Medical Technologies Guidance 13; MTG13).}
}

@book{xie2018a,
  title = {R Markdown: {{The}} Definitive Guide},
  author = {Xie, Yihui and Allaire, J.J. and Grolemund, Garrett},
  date = {2018},
  publisher = {{Chapman and Hall/CRC}},
  location = {{Boca Raton, Florida}},
  url = {https://bookdown.org/yihui/rmarkdown},
  isbn = {978-1-138-35933-8}
}

@book{xie2020,
  title = {R Markdown Cookbook},
  author = {Xie, Yihui and Dervieux, Christophe and Riederer, Emily},
  date = {2020},
  publisher = {{Chapman and Hall/CRC}},
  location = {{Boca Raton, Florida}},
  url = {https://bookdown.org/yihui/rmarkdown-cookbook},
  isbn = {978-0-367-56383-7}
}


