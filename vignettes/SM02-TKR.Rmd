---
title: "Markov model with probabilistic sensitivity analysis"
subtitle: "Computer-assisted total knee replacement"
author: "Paola Cognigni and Andrew Sims"
date: "February 2023"
bibliography: "../inst/REFERENCES.bib"
csl: "../inst/national-institute-of-health-research.csl"
output: 
  rmarkdown::html_vignette:
    fig_width: 7
    fig_height: 5
    fig_caption: true
    df_print: kable
vignette: >
  %\VignetteIndexEntry{Markov model with probabilistic sensitivity analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r}
#| purl = FALSE,
#| include = FALSE
# read vignette source chunks from corresponding testthat script
knitr::read_chunk("../tests/testthat/test-Model-TKR.R")
```

```{r}
#| purl = FALSE,
#| include = FALSE
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
pander::panderOptions("table.split.table", 200L)
```

```{r}
#| echo = FALSE
library(rdecision)
```
The article by Dong and Buxton, 2006 [-@dong2006] describes a Markov model for
the assessment of a new Computer-Assisted Surgery (CAS) technology for Total
Knee Replacement (TKR). This vignette follows their model to calculate the
cost-effectiveness of conventional and computer-assisted TKR surgery using
`rdecision`. 

# Modelling
The authors present both a point estimate and a probabilistic interpretation.
Both approaches are shown to highlight the similarities and differences when
using `rdecision`.

## Model description

### States
The patient journey is represented by 9 possible states, with each patient
assigned to exactly one state at any time:
```{r, state-names}
```

### Parameters
To assess cost effectiveness, the model must incorporate utilities and costs
for each state.

**Utilities** apply in a continuous manner: the longer the time a patient
spends in a particular state, the longer a particular utility value applies.
This is represented in `rdecision` by assigning the utility to a particular
`MarkovState`. This ensures that they are correctly scaled to different cycle
lengths, and that the annual discount rate is applied correctly.

```{r, utils-point}
```

**Costs**, in this case, represent one-time expenses associated with the
delivery of a surgical procedure, such as a TKR operation or a revision. As
such, they do not depend on the time the patient spends in a particular state,
and are represented by a cost assigned to a `Transition`. Ongoing costs that
apply as long as the patient remains in a state, for example medication, would
instead be assigned to the relevant `MarkovState`. The costs associated with
revisions/further treatments (states **E**, **F** and **G**) can be assigned to
the transitions from any other state into these states. For the cost of the
primary TKR operation (state **A**), the Markov model is designed with no
incoming transitions to the state, so the cost of this operation can be
included into the model by linking it to the transitions from **A** to other
states. When applying costs to transitions, it's important to consider the
possible transitions and ensure that no "double-counting" occurs (for example
by transitions that return to the same state).

```{r, costs-point}
```

## Point estimate
The initial deterministic analysis uses numerical best estimates for each
parameter (cost, utility, transition probability etc.). This results in a
model with an exact solution, but no estimate of the uncertainty, or of the
impact of individual parameters on the undertainty of the outcome.

### Markov model
The Markov state transition model specifies which transitions are permitted
between states. Each of the 9 states is represented in `rdecision` by a
`MarkovState` object, with a description, a state cost and a state utility.
Each allowed transition is represented by a `Transition` object, defined by
the source state, the target state, and a transition cost. In all cases, cost
defaults to 0.0 if not set, and utility to 1.0.

In their model, Dong and Buxton incorporate the cost of the CAS technology as
an additional cost attached to interventions - in this case, this would affect
`cost_A`, `cost_E` and `cost_F` (but not `cost_G` which represents non-surgical
procedures). Utilities are unchanged and therefore the same Markov state
definitions can be used by both models.

```{r, SMM-point}
```

To fully define a SemiMarkov model, we assign the States, Transitions, duration
of a cycle (as a `difftime` object) and, optionally, annual `discount.cost`
and `discount.utility`.

```{r, SMM-def-point}
```

```{r}
pander::pander(SMM_base$tabulate_states()[,c("Name", "Utility")], justify="ll")
```

The `SemiMarkovModel` object can be represented graphically in the DOT format
using the `asDOT()` method. The `DiagrammeR` package can then be used to plot
DOT files with the `grViz` function.

```{r} 
# wrapped in `try` to avoid error for users who don't have DiagrammeR installed
try(
  DiagrammeR::grViz(SMM_base$as_DOT(rankdir = "TB", width = 7.0, height = 5.0)),
  silent = TRUE
)
```

### Transition probabilities
For each allowed transition between a pair of states, probabilities are
reported in Table 2. These are added to the model using the
`set_probabilities` method, which takes for input a numerical matrix of size
N(states) x N(states).

For death outcomes, the probabilities are reported for *primary TKR*,
*TKR revision* and *all reasons*: for each state, the relevant probability of
death (transition to state **I**) will therefore be death(all reasons) + 
death(primary TKR *or* TKR revision). Note that Table 5 reports the death
rates for TKR-specific death (primary or revision), which can be recovered
by introducing separate Markov states in the model to represent the 3 possible
causes of death, each with relevant transitions.

The total sum of all outgoing transitions for each state must be 1, so one
transition per state should be calculated as 1 - sum(all other transitions).
This is also verified by the `set_probabilities` method that will return an
error if the probability matrix does not have row-wise sums of 1. Alternatively,
exactly one cell in each row can be left undefined as `NA` and it will
automatically be populated to ensure a row-wise total of 1.

```{r transitions-point}
```

The CAS technology affects patient outcomes by reducing the probability of
serious complications by about 34%. This applies to all transition
probabilities into state **B**, which correspond to column 2 in the transition
matrix. Note that this also requires adjusting the row-wise sum to 1, which
however is performed automatically by `set_probabilities` if one transition
per row is defined as `NA`.

```{r CAS-transitions-point}
```


### Running the model
The simulation described in the paper starts with 1000 patients and progresses
for 10 years, or 120 one-month cycles. At the start of the model, all patients
are in state **A**. The initial state of the simulation can be entered into
the model by applying the `reset` function with a named array describing the
number of simulated patients for each named state (in this case, 1000 in state
**A** and none in the other states).

The `cycles` function simulates the progress of the initial population through
the specified number of cycles, and, optionally, can apply half-cycle
correction to population and cost (`hcc.pop` and `hcc.cost`). In this example,
half-cycle correction is not used.

```{r cycle-point}
```

Running the `cycles` function returns a data frame with the population in each
state, the progress of the simulation (in cycles and years), the total cost
(including both transition and occupancy costs), and the calculated QALY. Costs
and QALYs are discounted by the rates specified in the model definition and are
normalised by the initial population.

The table below displays the first few cycles of the model, showing the
transition of patients from state **A** at cycle 0 (starting state) through the
3 allowed transitions to states **B**, **C** and **D**, and subsequently to
further states depending on their assigned transition probabilities. Each cycle
accrues a cost (the cost of TKR surgery is attached here to cycle 1, as it was
assigned to the transitions out of **A**) and this, with the utilities
associated with each state, can be used to calculate the QALY.

```{r}
pander::pander(SMM_base_10years[0L:5L,])
```
This progression can also be visualised using the base graphics function
`barplot`:

```{r}
plot_occupancy <- function(SMM) {
  states <- colnames(SMM)[
    !colnames(SMM) %in% c("Cost", "QALY", "Cycle", "Years")
  ]
  layout(matrix(c(1L, 2L), nrow = 1L), widths = c(0.6, 0.4))
  pal <- sample(hcl.colors(length(states), palette="Spectral"))
  barplot(t(as.matrix(SMM[,states])), 
          xlab="Cycle", ylab="States", names.arg=SMM[,"Cycle"],
          col=pal, border=NA, space=0L, main = "State occupancy progression")
  legend(
    "topleft", legend = states, fill = pal, bty = "n", 
    inset = c(1.05, 0.0), xpd = NA
  )
  layout(matrix(1L))
}
plot_occupancy(SMM_base_10years)
```

Dong and Buxton [-@dong2006] report results yearly (corresponding to cycles 12,
24, 36 etc.) with some cumulative values. The `cycles` function of 
`SemiMarkovModel` returns a Markov trace (state occupancies at the end of each
cycle, with per-cycle costs and QALYs) in the form of a data frame. The Markov
trace can be converted to their Table 4 form via the function `as_table4`. 
```{r, as-table4}
```

Replication of their Table 4 is given in the next two sections. Note that these
figures **do not match exactly** the published figures for costs and QALYs. This
might be a different application of the discount rate, or rounding errors
associated with the representation of currency in Excel. Small differences
in the CAS calculations can also probably be traced to rounding of the 34%
CAS effect figure.

#### Conventional surgery
```{r}
<<cs-table-4>>
pander::pander(
  t4_CS, round = 2L, row.names = FALSE, big.mark = ",", 
  justify = "lrrrrrrr", keep.trailing.zeros = TRUE
)
```

#### Computer-assisted surgery
```{r}
<<cas-table-4>>
pander::pander(
  CAS_t4, round=2L, row.names=FALSE, big.mark=",",
  justify="lrrrrrrr", keep.trailing.zeros=TRUE
)
```


## Probabilistic Sensitivity Analysis
PSA adds a randomisation-based process to estimate not only the central value
of the estimate, but also its uncertainty. This is done by representing
individual parameters not as single numerical values but as distributions,
from which a range of possible values can be extracted at random. The choice
of distribution type and parametrisation depend on the type of variable and the
values reported in the literature or observed in a relevant patient cohort.

### Parameter distributions

#### Utilities
These are constrained to a value between 0 and 1, and have been described with
a Beta distribution:

> A Beta function, with the mean equal to the point estimate and a high
  variance to reflect the uncertainty, was used to generate a random utility
  for each Markov state

The specific parameters for the distributions are not reported in the paper,
where instead a point estimate and a range (95% CI) are reported for each
utility distribution.

The Beta distribution can be parametrised using mean $\mu$ and sample size
$\nu$ (which relate to the more common parameters as $\alpha = \mu * \nu$
and $\beta = (1 - \mu) * \nu)$, using the point estimate as mean and assessing
numerically the sample size until the confidence intervals match the reported
range. Not all the ranges provided map to a valid Beta distribution with the
given mean, suggesting that the authors used a different method to derive their
Beta distributions. Note also that the authors report that 

> To ensure a plausible relationship between the utilities of states “Normal
  health after primary TKR,” “TKR with minor complications,” and “TKR with
  serious complications,” the process was structured so that the hierarchical
  relationship was retained but the differences between the utilities were
  randomly drawn from the distribution.

but there is no description of the method used and/or how the resulting values
are constrained to the [0, 1] interval.

```{r utilities-var}
```

These parameters can now be used to describe the distributions that each
utility value should be drawn from. This is represented in `rdecision` by a
`ModVar` variable, in this case specifically the `BetaModVar` child class. This
type of ModVar requires the `alpha` and `beta` parameters, which can be
calculated according to the equations above. Note that for state **I** (Death),
there is no need to define a ModVar, as the utility of this state is not
associated with any uncertainty.

```{r utilities-beta}
```

#### Costs
These can take any non-negative value, and have been described with a Gamma
distribution:

> Variance for the Gamma distribution was estimated from the ranges. A Gamma
  function was used to generate a random cost for each Markov state.

These distributions are also reported as means and 95% CI. In this case, the
means of the Gamma distributions are sufficiently far from 0 that the
approximation to a Gaussian distribution is acceptable to estimate the value
of the standard deviation.

The `GammaModVar` class requires the parameters `shape` and `scale`, which
relate to mean $\mu$ and variance $\sigma^2$ as $shape = \mu^2 / \sigma^2$
and $scale = \sigma^2 / \mu$.

```{r costs-gamma}
```

The cost of CAS is also modelled with a Gamma distribution, but in this case
the authors estimate the distribution parameters directly:

> We assumed that the ratio of its standard deviation over mean was four times
  as large as that of conventional primary TKR

As a result, the total cost of a surgical procedure is the sum of the surgery
cost and the CAS cost, each of which is independently drawn from a defined
gamma distribution. This can be easily represented in `rdecision` using an
`ExprModVar`: a model variable that uses other model variables as operands.
The expression needs to be quoted using the `rlang::quo` command in order to
be stored rather than executed straight away.

```{r cas-cost-gamma}
```

The CAS effect in this model is a reduction in the transition probabilities
to state **B**, and was modelled using a lognormal distribution:

> Lognormal function was used to generate a random “effect of CAS.” The
  variance of the “effect of CAS” was estimated from the clinical trials

Because a lognormally distributed value is always positive, the resulting
transition probabilities will be reduced by a non-zero fraction (note however
that values > 100% are possible, which would result an invalid negative
transition probability).

While it is possible to reconstruct the exact parameters of a lognormal
distribution given a mean and 95% CI, the article does not report a range for
this variable. Because exact replication is therefore impossible, an arbitrary
parametrisation is used here that is unlikely to yield an illegal value.

```{r cas-lognorm}
CAS_effect_mean <- 0.34
CAS_effect_sd <- 1.25
CAS_effect_lognorm <- LogNormModVar$new(
  "Effect of CAS", "", log(CAS_effect_mean), log(CAS_effect_sd)
)
```

### Markov model
The same structure as the model used for the deterministic solution can be
used again, but in this case the costs and utilities will be represented by
distributions.

```{r SMM-PSA}
```

The current model includes a number of model variables, that can be displayed
using the `modvar_table` method. This tabulation can also be used to compare
the 95% CI with the values reported in Table 3. 

```{r}
pander::pander(
  SMM_base_PSA$modvar_table()[,c(-2L, -5L, -9L)], justify="llrrrr", round=5L
)
```

Note that the list of ModVars associated with the CAS model includes not only
the variables that were explicitly assigned to States and Transitions, such as
*Utility of state A*, but also the implicit ModVars underlying ExprModVars,
such as *Cost of CAS*, which is used to calculate *Cost of state A with CAS*.

```{r}
pander::pander(
  SMM_CAS_PSA$modvar_table()[,c(-2L, -5L, -9L)], justify="llrrrr", round=5L
)
```

### Transition probabilities
> To generate a logical multi-Markov state probabilistic transition matrix from
  the initial point estimates, the Dirichlet distribution was used (11). We
  estimated a count for each Markov state by the transition probabilities (we
  assumed that the total counts equalled 1,000). We used random number and
  Gamma distribution formulae to generate a one-parameter (standard) Gamma
  distribution for each cell of the transition matrix. The one-parameter Gamma 
  distribution in Excel was obtained by setting the first (alpha) parameter
  equal to the estimated count and the second (beta) parameter equal to 1. The
  final step was to “normalize” the realizations from the Gamma distribution
  back to the 0–1 scale by dividing each realization through by the
  corresponding row total.

The complex description above is an approximation of a Dirichlet distribution 
when constrained by the functionalities of Excel. In `rdecision`, variables
drawn from a multinomial probabilistic distribution can be defined using
in-built functions:

* For each state, construct a `DirichletDistribution` from the known counts or
  proportions for each exiting transition. If using proportions, a population
  should also specified to correctly assign variance to the probabilistic
  distribution. In this example, the authors specified a population of 1000.
* For each state-specific distribution, draw a random realisation of the
  multivariate distribution (`sample()` method) and populate the allowed
  transitions with numerical values (`r()` method). This is performed by
  the `dirichletify` function.
* Repeat the process at every cycle to sample different outgoing transition
  probabilities from the distribution.

```{r fun-dirichlet}
```

### PSA runs
The following code executes 250 versions of the model for conventional surgery,
each of 120 cycles, and for each version the set of model variables are sampled
from their uncertainty distributions. The Markov trace for each run, in matrix
form, is added to an 3D array which stores the traces from all the runs. Note
that each trace has one more row than the number of cycles to store the state
populations at cycle zero. 

```{r cycle-PSA}
```  

Plotting some simulation examples shows how introducing a probabilistic
representation for the transition probabilities has led to some differences
in the progression through cycles:

```{r some-plots}
plot_occupancy(SMM_base_PSA_sim[,,1L])
plot_occupancy(SMM_base_PSA_sim[,,2L])
plot_occupancy(SMM_base_PSA_sim[,,3L])
```

In the case of CAS, there is an additional step in the simulation process due
to the fact that the transition probabilities into state **B** (column 2 in the
transition matrix) are modified by a multiplier, *Effect of CAS*, which is
itself drawn from a distribution. In this case, the relevant ModVar needs to be
randomised at every cycle, applied to the base transition matrix, and the
matrix then processed by `dirichletify`. Because this function can correctly
complete the proportions to a total of 1 as long as one element of each row
is set to `NA`, the other transitions do not need to be modified manually.

```{r cycle-PSA-CAS}
```  

### Results
The means of the cohort simulation results should be very similar, but not
necessarily identical, to those in Table 4 (and replicated analytically above).
Each run of this script is expected to yield a slightly different result.

#### Conventional surgery
```{r, t4-PSA-CAS}
```


```{r cohort-simulation-results}
#cum_SMM_base_PSA <- apply(SMM_base_PSA_sim, c(2L,3L), cumsum)
#yearly <- (0L:10L)* 12L + 1L 
#
#data_summary <- function(data) {
#  return(
#    c(
#      "Mean" = mean(data),
#      "SD" = sd(data),
#      "Q2.5" = quantile(data, 0.025, names = FALSE),
#      "Q97.5" = quantile(data, 0.975, names = FALSE)
#    )
#  )
#}
#summ_base_PSA <- aperm(
#  apply(SMM_base_PSA_sim[yearly,,], c(1L,2L), data_summary), c(2L,3L,1L)
#)
#cumsumms_base_PSA <- aperm(
#  apply(cum_SMM_base_PSA[yearly,,], c(1L,2L), data_summary), c(2L,3L,1L)
#)
#
#i <- "Mean"
#dong_output_simulation <- data.frame(
#  "Year" = summ_base_PSA[,,i][,"Cycle"] / 12L,
#  # Table 4 shows % while here numbers are calculated per N = 1000 patients,
#  # so divide by 10
#  "Cumulative serious complication (%)" =
#    cumsumms_base_PSA[,states["B"],i] / 10L,
#  "Cumulative minor complication (%)" =
#    cumsumms_base_PSA[,states["C"],i] / 10L,
#  "Cumulative complex revision (%)" =
#    cumsumms_base_PSA[,states["E"],i] / 10L,
#  "Cumulative simple revision (%)" =
#    cumsumms_base_PSA[,states["F"],i] / 10L,
#  # no need to use cumulative sum of deaths as each patient only enters
#  # this state once
#  "Cumulative death (%)" = summ_base_PSA[,states["I"],i] / 10L,
#  # multiply by N = 1000 to reverse the normalisation by population
#  "Discounted costs (£)" = cumsumms_base_PSA[,"Cost",i] * 1000L,
#  "Discounted QALYs" = cumsumms_base_PSA[,"QALY",i] * 1000L,
#  check.names = FALSE
#)
#pander::pander(
#  dong_output_simulation, round=2L, row.names=FALSE, big.mark=",",
#  justify="lrrrrrrr", keep.trailing.zeros=TRUE
#)
pander::pander(
  t4_CS_PSA_mean, round=2L, row.names=FALSE, big.mark=",",
  justify="lrrrrrrr", keep.trailing.zeros=TRUE
)
```

**Computer-assisted surgery**

```{r cohort-simulation-CAS-results}
#cum_SMM_CAS_PSA <- apply(SMM_CAS_PSA_sim, c(2L,3L), cumsum)
#summ_CAS_PSA <- aperm(
#  apply(SMM_CAS_PSA_sim[yearly,,], c(1L,2L), data_summary), c(2L,3L,1L)
#)
#cumsumms_CAS_PSA <- aperm(
#  apply(cum_SMM_CAS_PSA[yearly,,], c(1L,2L), data_summary), c(2L,3L,1L)
#)

#i <- "Mean"
#dong_output_simulation <- data.frame(
#  "Year" = summ_CAS_PSA[,,i][,"Cycle"] / 12L,
#  # Table 4 shows % while here numbers are calculated per N = 1000 patients,
#  # so divide by 10
#  "Cumulative serious complication (%)" =
#    cumsumms_CAS_PSA[,states["B"],i] / 10L,
#  "Cumulative minor complication (%)" =
#    cumsumms_CAS_PSA[,states["C"],i] / 10L,
#  "Cumulative complex revision (%)" =
#    cumsumms_CAS_PSA[,states["E"],i] / 10L,
#  "Cumulative simple revision (%)" =
#    cumsumms_CAS_PSA[,states["F"],i] / 10L,
#  # no need to use cumulative sum of deaths as each patient only
#  # enters this state once
#  "Cumulative death (%)" = summ_CAS_PSA[,states["I"],i] / 10L,
#  # multiply by N = 1000 to reverse the normalisation by population
#  "Discounted costs (£)" = cumsumms_CAS_PSA[,"Cost",i] * 1000L,
#  "Discounted QALYs" = cumsumms_CAS_PSA[,"QALY",i] * 1000L,
#  check.names = FALSE
#)

#pander::pander(
#  dong_output_simulation, round=2L, row.names=FALSE, big.mark=",",
#  justify="lrrrrrrr", keep.trailing.zeros=TRUE
#)
```

The addition of probabilistic elements can be used to compare not only the means, but also the uncertainties associated with the two models.

```{r cohort-simulation-vars}
#cols <- grepl("serious|[xe] revision", colnames(cumsumms_base_PSA))
#pander::pander(
#  cumsumms_base_PSA[11L, cols,]/10L, "Conventional TKR", justify="lrrrr"
#)
#pander::pander(
#  cumsumms_CAS_PSA[11L, cols,]/10L, "Computer-assisted TKR", justify="lrrrr"
#)
```

Note that the means correlate well with those reported in Table 5, but the assertion that "[CAS] had lower variances for each indicator" is not reliably replicated for every variable. This is likely to be due to the fact that the parameters for the distribution of the *Effect of CAS* could not be extracted, and the values chosen here may assign excessive uncertainty to this variable.


```{r exit, echo=FALSE}
knitr::knit_exit()
```


versions with modvar extractions (for analysis of covariance)

```{r cycle-PSA-with-modvar-table}
nruns <- 50L
ncycles <- 120L
SMM_base_PSA_sim <- list()
SMM_base_PSA_mvs <- list()

for (run in seq_len(nruns)) {
  # reset and randomise every run
  SMM_base_PSA$reset(populations)
  # randomise all other ModVars
  for (mv in SMM_base_PSA$modvars()) mv$set("random")
  # set the transition matrix 
  Pt_cycle <- dirichletify(Pt, population=1000L)
  SMM_base_PSA$set_probabilities(Pt_cycle)
  run_results <- SMM_base_PSA$cycles(
    ncycles=120L, hcc.pop=FALSE, hcc.cost=FALSE
  )
  run_modvars <- SMM_base_PSA$modvar_table()
  SMM_base_PSA_sim[[run]] <- as.matrix(run_results)
  SMM_base_PSA_mvs[[run]] <- as.matrix(run_modvars[,4L:8L])
}

SMM_base_PSA_sim <- simplify2array(SMM_base_PSA_sim)
SMM_base_PSA_mvs <- simplify2array(SMM_base_PSA_mvs)
dimnames(SMM_base_PSA_mvs)[[1L]] <- run_modvars$Description
```  


```{r cycle-PSA-CAS-with-modvar-table}
SMM_CAS_PSA_sim <- list()
SMM_CAS_PSA_mvs <- list()

for (run in seq_len(nruns)) {
  # reset and randomise every run
  SMM_CAS_PSA$reset(populations)
  # randomise all SMM ModVars
  for (mv in SMM_base_PSA$modvars()) mv$set("random")
  # randomise and draw the CAS_effect_lognorm ModVar
  CAS_effect_lognorm$set("random")
  CAS_effect <- CAS_effect_lognorm$get()
  # apply CAS_effect to column 2 of the transition matrix
  Pt_CAS <- Pt
  Pt_CAS[,2L] <- Pt_CAS[,2L] * (1.0 - CAS_effect)
  # set the transition matrix 
  Pt_cycle <- dirichletify(Pt_CAS, population=1000L)
  SMM_CAS_PSA$set_probabilities(Pt_cycle)
  run_results <- SMM_CAS_PSA$cycles(
    ncycles=120L, hcc.pop=FALSE, hcc.cost=FALSE
  )
  run_modvars <- SMM_CAS_PSA$modvar_table()
  # manually add the CAS_effect modvar to the tabulation
  run_modvars <- rbind(run_modvars, data.frame(
    Description = CAS_effect_lognorm$description(),
    Units = CAS_effect_lognorm$units(),
    Distribution = CAS_effect_lognorm$distribution(),
    Mean = CAS_effect_lognorm$mean(),
    E = CAS_effect_lognorm$mean(),
    SD = CAS_effect_lognorm$SD(),
    Q2.5 = CAS_effect_lognorm$quantile(probs=0.025),
    Q97.5 = CAS_effect_lognorm$quantile(probs=0.975),
    Est = CAS_effect_lognorm$is_expression()
  ))
  # TODO the modvar_table method does not belong in SMM - either a 
  # ModVarCollection
  # class or a summary method for ModVar that returns a named array and the
  # modvar_table method just rbinds it
  SMM_CAS_PSA_sim[[run]] <- as.matrix(run_results)
  SMM_CAS_PSA_mvs[[run]] <- as.matrix(run_modvars[,4L:8L])
}

SMM_CAS_PSA_sim <- simplify2array(SMM_CAS_PSA_sim)
SMM_CAS_PSA_mvs <- simplify2array(SMM_CAS_PSA_mvs)
dimnames(SMM_CAS_PSA_mvs)[[1L]] <- run_modvars$Description

```  

```{r plots}
dcost <- cum_SMM_CAS_PSA[121L,"Cost",] - cum_SMM_base_PSA[121L,"Cost",]
dqaly <- cum_SMM_CAS_PSA[121L,"QALY",] - cum_SMM_base_PSA[121L,"QALY",]
plot(dcost ~ dqaly)
```






There is something else I don't understand with the costs:  
All costs here are modelled as transition costs (which I expect to be independent of cycle length); all Occupancy costs are 0. We ignore cycle 1 because the only allowed transitions are from A to B, C or D, all with no cost. This is cycle 2 which shows some transitions to costed states (E, F, G):

```{r cycle-1}
SMM$reset(populations)
# run first cycle but ignore
SMM$cycle(FALSE, FALSE)
# print cycle 2
pander::pander(SMM$cycle(FALSE, FALSE)[,c(-2L, -3L)])
```

For ex.: row G (other treatments) has a stated cost of £2844. EntryCost should presumably be population * cost = 14.97 * £2844 = £42,574.68 but it's instead *exactly* 1/9th. Where does this come from? Is it due to there being 9 possible states?  
Costs (total) looks correct after population correction (/1000).


### Issues:

- All distributions are reported as point estimate (range) but there is no explanation of what this range represents (ranges are assumed to be 95% CI? how has the asymmetry been incorporated to estimate shape?) and the actual parameters are not reported anywhere 
- Costs are parametrised as Gamma with "variance ... estimated from the ranges" but the way in which this was done is not described 
- Utilities have been modelled as Beta with "a high variance to reflect the uncertainty" (no more info given)
- The utilities of normal health, minor complications and serious complications have been modelled "so that the hierarchical relationship was retained but the differences between the utilities were randomly drawn from the distribution" (not clear to me how this would remain within the 0-1 range, or did they just swap the utilities if in the wrong order?)
- The cost of the intervention is never stated (could conceivably be reverse-engineered from the results if problems above are solved)
- The parameters for the effect of the intervention are not described (the point estimate is given, but the variance is "estimated from the clinical trials" although not even a range is reported)

```{r SMM-point-old, eval=FALSE}

# Markov states
sA <- MarkovState$new(states["A"], cost=cost_A, utility=utility_A)
sB <- MarkovState$new(states["B"], cost=cost_B, utility=utility_B)
sC <- MarkovState$new(states["C"], cost=cost_C, utility=utility_C)
sD <- MarkovState$new(states["D"], cost=cost_D, utility=utility_D)
sE <- MarkovState$new(states["E"], cost=cost_E, utility=utility_E)
sF <- MarkovState$new(states["F"], cost=cost_F, utility=utility_F)
sG <- MarkovState$new(states["G"], cost=cost_G, utility=utility_G)
sH <- MarkovState$new(states["H"], cost=cost_H, utility=utility_H)
sI <- MarkovState$new(states["I"], cost=cost_I, utility=utility_I)

States <- do.call(list, mget(grep("^s[A-I]$", ls(), value = TRUE)))

# Transitions
tAD <- Transition$new(sA, sD)
tAC <- Transition$new(sA, sC)
tAB <- Transition$new(sA, sB)
tBC <- Transition$new(sB, sC)
tBE <- Transition$new(sB, sE)
tBF <- Transition$new(sB, sF)
tBG <- Transition$new(sB, sG)
tCB <- Transition$new(sC, sB)
tCD <- Transition$new(sC, sD)
tCF <- Transition$new(sC, sF)
tCG <- Transition$new(sC, sG)
tCC <- Transition$new(sC, sC)
tDC <- Transition$new(sD, sC)
tDB <- Transition$new(sD, sB)
tDD <- Transition$new(sD, sD)
tEB <- Transition$new(sE, sB)
tEH <- Transition$new(sE, sH)
tFB <- Transition$new(sF, sB)
tFC <- Transition$new(sF, sC)
tFG <- Transition$new(sF, sG)
tFH <- Transition$new(sF, sH)
tGB <- Transition$new(sG, sB)
tGC <- Transition$new(sG, sC)
tGF <- Transition$new(sG, sF)
tGD <- Transition$new(sG, sD)
tHE <- Transition$new(sH, sE)
tHF <- Transition$new(sH, sF)
tHH <- Transition$new(sH, sH)
tBI <- Transition$new(sB, sI)
tCI <- Transition$new(sC, sI)
tDI <- Transition$new(sD, sI)
tEI <- Transition$new(sE, sI)
tFI <- Transition$new(sF, sI)
tGI <- Transition$new(sG, sI)
tHI <- Transition$new(sH, sI)
tII <- Transition$new(sI, sI)

Transitions <- do.call(list, mget(grep("^t[A-I]{2}$", ls(), value = TRUE)))

SMM <- SemiMarkovModel$new(
  V = States, E = Transitions,
  tcycle = as.difftime(365.25/12L, units = "days"), # cycles in months
  discount.cost = 0.035/12L,
  discount.utility = 0.035/12L
)

pander::pander(SMM$tabulate_states()[,c("Name", "Cost")], justify="llr")
DiagrammeR::grViz(SMM$as_DOT())
```
